#!/usr/bin/env python3
# main.py
import logging
import os
import json
from typing import Optional, List

import torch
import hydra
from omegaconf import DictConfig, OmegaConf

from utils.logging import ExperimentLogger, get_logger

from core import (
    create_student_by_name,
    create_teacher_by_name,
    run_training_stages,
    run_continual_learning,
    renorm_ce_kd,
    setup_partial_freeze_schedule_with_cfg,
    setup_safety_switches_with_cfg,
    auto_set_ib_mbm_query_dim_with_model,
    cast_numeric_configs,
)

from utils.common import (
    set_random_seed,
    check_label_range,
    get_model_num_classes,
)

from data.cifar100 import get_cifar100_loaders
from data.imagenet32 import get_imagenet32_loaders
from modules.partial_freeze import apply_partial_freeze

try:
    import wandb
except ModuleNotFoundError:
    wandb = None


def _to_dict(cfg: DictConfig):
    return OmegaConf.to_container(cfg, resolve=True)

def normalize_exp(exp: dict):
    """Flatten any remaining nesting in experiment config and promote method values to top level"""
    if isinstance(exp, dict):
        # dataset/schedule/methodê°€ ì´ì¤‘ ì¤‘ì²©ì´ë©´ í‰íƒ„í™”
        for k in ("dataset", "schedule", "method"):
            v = exp.get(k)
            if isinstance(v, dict) and k in v and isinstance(v[k], dict):
                exp[k] = v[k]
        
        # teacher1, teacher2, model.studentì˜ ì¤‘ì²©ë„ í‰íƒ„í™”
        for k in ("teacher1", "teacher2"):
            v = exp.get(k)
            if isinstance(v, dict) and k in v and isinstance(v[k], dict):
                exp[k] = v[k]
        
        # model.student ì¤‘ì²© í‰íƒ„í™”
        model = exp.get("model", {})
        if isinstance(model, dict):
            student = model.get("student", {})
            if isinstance(student, dict) and "student" in student and isinstance(student["student"], dict):
                model["student"] = student["student"]
        
        # method ê°’ì„ ìµœìƒìœ„ë¡œ ë°˜ì˜(ì´ë¦„ ì œì™¸ ì„ íƒ)
        if isinstance(exp.get("method"), dict):
            for mk, mv in exp["method"].items():
                if mk != "name" and mk not in exp:
                    exp[mk] = mv
    
    return exp


def _log_and_save_meta(logger, exp_logger: ExperimentLogger, exp: dict,
                       t1_name: str, t2_name: str, s_name: str,
                       t1_acc: float = 0.0, t2_acc: float = 0.0):
    """Print a concise experiment metadata banner and write meta.json."""
    method_cfg = exp.get("method", {}) or {}
    kd_method = method_cfg.get("name", "asib")
    dataset = exp.get("dataset", {}) or {}
    schedule = exp.get("schedule", {}) or {}
    student_cfg = (exp.get("model", {}) or {}).get("student", {}) or {}

    meta = {
        "exp_id": exp.get("exp_id"),
        "seed": exp.get("seed", 42),
        "dataset": {
            "name": dataset.get("name"),
            "batch_size": dataset.get("batch_size"),
            "num_workers": dataset.get("num_workers"),
            "data_aug": dataset.get("data_aug", 1),
        },
        "teachers": [
            {"name": t1_name, "ckpt": exp.get("teacher1_ckpt"), "test_acc": round(float(t1_acc or 0.0), 2)},
            {"name": t2_name, "ckpt": exp.get("teacher2_ckpt"), "test_acc": round(float(t2_acc or 0.0), 2)},
        ],
        "student": {
            "name": s_name,
            "pretrained": bool(student_cfg.get("pretrained", False)),
            "use_adapter": bool(student_cfg.get("use_adapter", False)),
        },
        "kd": {
            "method": kd_method,
            "ce_alpha": exp.get("ce_alpha"),
            "kd_alpha": exp.get("kd_alpha", 0.0),
            "kd_ens_alpha": exp.get("kd_ens_alpha", 0.0),
            "teacher_adapt_kd_warmup": exp.get("teacher_adapt_kd_warmup", 0),
        },
        "ib": {
            "use_ib": exp.get("use_ib", False),
            "ib_beta": exp.get("ib_beta"),
            "ib_epochs_per_stage": exp.get("ib_epochs_per_stage"),
            "ib_mbm_out_dim": exp.get("ib_mbm_out_dim"),
            "ib_mbm_n_head": exp.get("ib_mbm_n_head"),
        },
        "cccp": {
            "use_cccp": exp.get("use_cccp", False),
        },
        "optim": {
            "optimizer": exp.get("optimizer", "adamw"),
            "student_lr": exp.get("student_lr"),
            "student_weight_decay": exp.get("student_weight_decay"),
            "grad_clip_norm": exp.get("grad_clip_norm", 0),
        },
        "schedule": {
            "type": schedule.get("type"),
            "lr_warmup_epochs": schedule.get("lr_warmup_epochs"),
            "min_lr": schedule.get("min_lr"),
            "step_size": schedule.get("step_size"),
            "gamma": schedule.get("gamma"),
        },
        "cl": {
            "cl_mode": exp.get("cl_mode", False),
            "cl_method": (exp.get("cl_method", "asib_cl") if exp.get("cl_mode", False) else None),
        },
        "amp": {
            "use_amp": exp.get("use_amp", False),
            "amp_dtype": exp.get("amp_dtype"),
        },
        "ppf": {
            "use_partial_freeze": exp.get("use_partial_freeze", False),
            "use_teacher_finetuning": exp.get("use_teacher_finetuning", False),
            "student_freeze_level": exp.get("student_freeze_level", -1),
            "teacher1_freeze_level": exp.get("teacher1_freeze_level", -1),
            "teacher2_freeze_level": exp.get("teacher2_freeze_level", -1),
            "student_freeze_bn": exp.get("student_freeze_bn", False),
            "teacher1_freeze_bn": exp.get("teacher1_freeze_bn", True),
            "teacher2_freeze_bn": exp.get("teacher2_freeze_bn", True),
        },
    }

    banner = [
        "================= EXPERIMENT META =================",
        f"ExpID          : {meta['exp_id']}",
        f"Dataset        : {meta['dataset']['name']} | BS={meta['dataset']['batch_size']} | Aug={meta['dataset']['data_aug']}",
        f"Teacher1       : {t1_name} | ckpt={exp.get('teacher1_ckpt')} | acc={meta['teachers'][0]['test_acc']:.2f}%",
        f"Teacher2       : {t2_name} | ckpt={exp.get('teacher2_ckpt')} | acc={meta['teachers'][1]['test_acc']:.2f}%",
        f"Student        : {s_name} | pretrained={meta['student']['pretrained']} | adapter={meta['student']['use_adapter']}",
        f"KD             : {meta['kd']['method']} | ce={meta['kd']['ce_alpha']} kd={meta['kd']['kd_alpha']} ens={meta['kd']['kd_ens_alpha']} warmup={meta['kd']['teacher_adapt_kd_warmup']}",
        f"IB/CCCP        : use_ib={meta['ib']['use_ib']} Î²={meta['ib']['ib_beta']} ib_ep={meta['ib']['ib_epochs_per_stage']} (out={meta['ib']['ib_mbm_out_dim']} n_head={meta['ib']['ib_mbm_n_head']}) | use_cccp={meta['cccp']['use_cccp']}",
        f"PPF            : partial_freeze={meta['ppf']['use_partial_freeze']} t_finetune={meta['ppf']['use_teacher_finetuning']} | s_freeze={meta['ppf']['student_freeze_level']} t1_freeze={meta['ppf']['teacher1_freeze_level']} t2_freeze={meta['ppf']['teacher2_freeze_level']} | bn(s/t1/t2)={meta['ppf']['student_freeze_bn']}/{meta['ppf']['teacher1_freeze_bn']}/{meta['ppf']['teacher2_freeze_bn']}",
        f"Optim/Sched    : {meta['optim']['optimizer']} lr={meta['optim']['student_lr']} wd={meta['optim']['student_weight_decay']} | sch={meta['schedule']['type']}",
        f"AMP            : use_amp={meta['amp']['use_amp']} dtype={meta['amp']['amp_dtype']}",
        f"CL             : cl_mode={meta['cl']['cl_mode']} method={meta['cl']['cl_method']}",
        "===================================================",
    ]
    for line in banner:
        logger.info(line)
    exp_logger.save_meta(meta)
    # PPF ì„¤ì • ë¶ˆì¼ì¹˜ ê²½ê³ 
    if not meta["ppf"]["use_partial_freeze"] and any(lv != -1 for lv in [meta["ppf"]["student_freeze_level"], meta["ppf"]["teacher1_freeze_level"], meta["ppf"]["teacher2_freeze_level"]]):
        logger.warning("[PPF] use_partial_freeze=Falseì´ì§€ë§Œ freeze_level!= -1 ì„¤ì •ì´ ê°ì§€ë˜ì—ˆìŠµë‹ˆë‹¤. ì„¤ì • í™•ì¸ í•„ìš”.")
    
    # Also persist a few meta fields into CSV summary
    exp_logger.update_metric("optimizer", meta["optim"]["optimizer"])
    exp_logger.update_metric("student_lr", meta["optim"]["student_lr"])
    exp_logger.update_metric("student_weight_decay", meta["optim"]["student_weight_decay"])
    exp_logger.update_metric("kd_alpha", meta["kd"]["kd_alpha"])
    exp_logger.update_metric("ce_alpha", meta["kd"]["ce_alpha"])
    exp_logger.update_metric("use_ib", int(bool(meta["ib"]["use_ib"])) )
    exp_logger.update_metric("ib_beta", meta["ib"]["ib_beta"]) 
    exp_logger.update_metric("ib_epochs_per_stage", meta["ib"]["ib_epochs_per_stage"]) 
    exp_logger.update_metric("use_cccp", int(bool(meta["cccp"]["use_cccp"])) )
    
    # PPF ì •ë³´ë„ CSVì— ì¶”ê°€
    exp_logger.update_metric("use_partial_freeze", int(bool(meta["ppf"]["use_partial_freeze"])))
    exp_logger.update_metric("use_teacher_finetuning", int(bool(meta["ppf"]["use_teacher_finetuning"])))
    exp_logger.update_metric("student_freeze_level", meta["ppf"]["student_freeze_level"])
    exp_logger.update_metric("teacher1_freeze_level", meta["ppf"]["teacher1_freeze_level"])
    exp_logger.update_metric("teacher2_freeze_level", meta["ppf"]["teacher2_freeze_level"])


@torch.no_grad()
def _quick_eval(model: torch.nn.Module, loader, device: str) -> float:
    """Lightweight top-1 accuracy eval on a dataloader."""
    model.eval()
    correct = 0
    total = 0
    for x, y in loader:
        x, y = x.to(device), y.to(device)
        out = model(x)
        # unwrap logits from common wrappers
        if isinstance(out, tuple):
            logits = out[1]
        elif isinstance(out, dict) and "logit" in out:
            logits = out["logit"]
        else:
            logits = out
        pred = logits.argmax(dim=1)
        correct += (pred == y).sum().item()
        total += y.size(0)
    return 100.0 * correct / max(1, total)

@hydra.main(config_path="configs", version_base="1.3")
def main(cfg: DictConfig):
    # 1) experiment ì„œë¸ŒíŠ¸ë¦¬ë§Œ ì‚¬ìš© (nested experiment ë°©ì–´)
    exp = cfg.experiment if "experiment" in cfg else cfg
    # If composed config nests another 'experiment', unwrap it
    try:
        if isinstance(exp, DictConfig) and "experiment" in exp and isinstance(exp.experiment, (DictConfig, dict)):
            exp = exp.experiment
    except Exception:
        pass
    exp_dict = _to_dict(exp)

    # 2-a) ë£¨íŠ¸ í‚¤ ì˜¤ë²„ë¼ì´ë“œ ë³‘í•© ì§€ì›: -cnìœ¼ë¡œ experiment ì„ íƒ ì‹œì—ë„
    # root ìˆ˜ì¤€ì˜ ì˜¤ë²„ë¼ì´ë“œ(ì˜ˆ: seed=42, kd_alpha=0.3)ë¥¼ expë¡œ ë³‘í•©í•œë‹¤.
    try:
        root_dict = _to_dict(cfg)
        for rk, rv in list(root_dict.items()):
            if rk in ("experiment", "hydra", "defaults"):
                continue
            # ë£¨íŠ¸ ì˜¤ë²„ë¼ì´ë“œëŠ” ì‹¤í—˜ ê¸°ë³¸ê°’ì„ ë®ì–´ì“´ë‹¤
            exp_dict[rk] = rv
    except Exception:
        pass
    
    # 2) ì¤‘ì²© í‰íƒ„í™”
    exp_dict = normalize_exp(exp_dict)

    # 2-a) method.* ì”ì¡´ í‚¤ë¡œ ì¸í•œ ì¶©ëŒ ë°©ì§€:
    # normalize_expëŠ” methodì˜ ê°’ì„ ìµœìƒìœ„ì— ì±„ìš°ë˜(ì—†ì„ ë•Œë§Œ)
    # ì”ì¡´ method ì„œë¸ŒíŠ¸ë¦¬ê°€ ë‚¨ì•„ìˆìœ¼ë©´ ì¼ë¶€ ëª¨ë“ˆì´ cfg["method"]ë¥¼ ì°¸ì¡°í•´
    # ì˜ë„ì¹˜ ì•Šê²Œ ë‹¤ë¥¸ í•˜ì´í¼íŒŒë¼ë¯¸í„°ë¥¼ ì‚¬ìš©í•  ìˆ˜ ìˆë‹¤.
    # í˜¼ì„ ì„ ë°©ì§€í•˜ê¸° ìœ„í•´ method ì„œë¸ŒíŠ¸ë¦¬ë¥¼ ì œê±°í•œë‹¤.
    try:
        if isinstance(exp_dict.get("method"), dict):
            exp_dict.pop("method", None)
    except Exception:
        pass

    # 2-b) í•™ìŠµ ìŠ¤ì¼€ì¤„ í‚¤ ì •ê·œí™”: trainer ëª¨ë“ˆì´ ê¸°ëŒ€í•˜ëŠ” í‚¤ë¡œ ë§¤í•‘
    # student_epochs_per_stage -> student_epochs_schedule
    if "student_epochs_per_stage" in exp_dict and "student_epochs_schedule" not in exp_dict:
        try:
            sel = exp_dict.get("student_epochs_per_stage")
            if isinstance(sel, (list, tuple)) and len(sel) > 0:
                exp_dict["student_epochs_schedule"] = list(sel)
                # student_iters fallbackë„ ë™ì¼ ê°’ìœ¼ë¡œ ì„¤ì •í•˜ì—¬ 1 epochë¡œ ê³ ì •ë˜ëŠ” ê²ƒ ë°©ì§€
                exp_dict["student_iters"] = int(sel[0])
        except Exception:
            pass

    # 2-b-1) ê°„ë‹¨ ì˜¤ë²„ë¼ì´ë“œ ì§€ì›: student_epochs, stages
    # ì‚¬ìš© ì˜ˆ) +experiment.student_epochs=5 +experiment.stages=1
    if "stages" in exp_dict:
        try:
            exp_dict["num_stages"] = int(exp_dict["stages"])
        except Exception:
            pass
    if "student_epochs" in exp_dict:
        try:
            se = int(exp_dict["student_epochs"])
            # num_stagesê°€ ì•„ì§ ì •í•´ì§€ì§€ ì•Šì•˜ë‹¤ë©´ 1ë¡œ ê°€ì •
            ns = int(exp_dict.get("num_stages", 1))
            exp_dict["student_epochs_schedule"] = [se for _ in range(ns)]
            exp_dict["student_iters"] = se
        except Exception:
            pass

    # 2-b-2) ê°„ë‹¨ ì˜¤ë²„ë¼ì´ë“œ ì§€ì›: dataset_batch_size (ì¤‘ì²© struct íšŒí”¼)
    # ì‚¬ìš© ì˜ˆ) +experiment.dataset_batch_size=16
    if "dataset_batch_size" in exp_dict:
        try:
            bs = int(exp_dict["dataset_batch_size"])
            if not isinstance(exp_dict.get("dataset"), dict):
                exp_dict["dataset"] = {}
            exp_dict["dataset"]["batch_size"] = bs
        except Exception:
            pass

    # 2-c) ì•ˆì „ì¥ì¹˜: num_stages ë³´ì •
    if "num_stages" not in exp_dict and "student_epochs_schedule" in exp_dict:
        try:
            exp_dict["num_stages"] = int(len(exp_dict["student_epochs_schedule"]))
        except Exception:
            exp_dict["num_stages"] = 1

    # 3) ë¡œê±°
    exp_dir = exp_dict.get("results_dir", ".")
    logger = get_logger(exp_dir, level=exp_dict.get("log_level", "INFO"))
    # Effective config (post-normalize) quick check
    try:
        logger.info(
            "[CFG] kd_target=%s ce=%s kd=%s ib_beta=%s",
            str(exp_dict.get("kd_target")),
            str(exp_dict.get("ce_alpha")),
            str(exp_dict.get("kd_alpha")),
            str(exp_dict.get("ib_beta")),
        )
    except Exception:
        pass
    # Clean internal/derived keys from HParams for clarity
    _hp = {k: v for k, v in exp_dict.items()}
    for _k in ("student_epochs_schedule", "student_iters", "stages", "student_epochs", "dataset_batch_size"):
        if _k in _hp:
            _hp.pop(_k, None)
    logger.info("HParams:\n%s", json.dumps(_hp, indent=2))

    # 3) W&B (ì˜µì…˜)
    if exp_dict.get("use_wandb", False):
        if wandb is None:
            logger.warning("[W&B] wandb not installed â€“ skipping")
        else:
            wandb.init(
                project=exp_dict.get("wandb_project", "kd_monitor"),
                entity=exp_dict.get("wandb_entity"),
                name=exp_dict.get("wandb_run_name", exp_dict.get("exp_id", "run")),
                config=exp_dict,
            )
            logger.info("[W&B] %s", wandb.run.url)

    # 4) ìˆ«ì ìºìŠ¤íŒ…/ì•ˆì „ ìŠ¤ìœ„ì¹˜
    cast_numeric_configs(exp_dict)

    # 5) ë¡œê·¸ ì €ì¥ê¸°
    exp_logger = ExperimentLogger(exp_dict, exp_name="asib")

    # 6) ë””ë°”ì´ìŠ¤/ì‹œë“œ
    device = exp_dict.get("device", "cuda")
    if device == "auto":
        device = "cuda" if torch.cuda.is_available() else "cpu"
    elif device == "cuda" and not torch.cuda.is_available():
        logger.warning("CUDA not available. Falling back to CPU.")
        device = "cpu"

    set_random_seed(exp_dict.get("seed", 42), deterministic=exp_dict.get("deterministic", True))
    
    # 6.5) CUDA ìµœì í™” ì„¤ì • (ì±„ë„-ë¼ìŠ¤íŠ¸, TF32, cuDNN)
    if device == "cuda" and torch.cuda.is_available():
        # cuDNN ë²¤ì¹˜ë§ˆí¬ ëª¨ë“œ í™œì„±í™” (Conv ì—°ì‚° ìë™ ìµœì í™”)
        torch.backends.cudnn.benchmark = True
        # TF32 í™œì„±í™” (A100/3090ì—ì„œ Conv/Matmul ê°€ì†)
        torch.backends.cuda.matmul.allow_tf32 = True
        torch.backends.cudnn.allow_tf32 = True
        # Float32 matmul precision ì„¤ì •
        torch.set_float32_matmul_precision("high")
        logger.info("CUDA optimizations enabled: cuDNN benchmark, TF32, high precision matmul")

    # 7) ë°ì´í„° ë¡œë”
    ds_cfg = exp_dict.get("dataset", {})
    dataset_name = ds_cfg.get("name", "cifar100")
    data_root = ds_cfg.get("root", "./data")
    batch_size = int(ds_cfg.get("batch_size", 128))
    num_workers = int(ds_cfg.get("num_workers", 2))
    data_aug = ds_cfg.get("data_aug", True)
    small_input = bool(exp_dict.get("small_input", ds_cfg.get("small_input", dataset_name == "cifar100")))

    if exp_dict.get("overlap_pct", -1) >= 0:
        from data.cifar100_overlap import get_overlap_loaders, CIFAR100OverlapDataset
        (A_tr, A_te), (B_tr, B_te), _ = get_overlap_loaders(
            pct_overlap=exp_dict["overlap_pct"],
            batch_size=batch_size,
            num_workers=num_workers,
            augment=data_aug,
            seed=exp_dict.get("seed", 42),
        )
        base_train_loader, base_test_loader = get_cifar100_loaders(
            root=data_root, batch_size=batch_size, num_workers=num_workers, augment=data_aug
        )
        all_classes = sorted(list(set(A_tr.dataset.class_indices + B_tr.dataset.class_indices)))
        combined_train_dataset = CIFAR100OverlapDataset(base_train_loader.dataset, all_classes)
        combined_test_dataset = CIFAR100OverlapDataset(base_test_loader.dataset, all_classes)
        train_loader = torch.utils.data.DataLoader(
            combined_train_dataset, batch_size=batch_size, shuffle=True, num_workers=num_workers, pin_memory=True
        )
        test_loader = torch.utils.data.DataLoader(
            combined_test_dataset, batch_size=batch_size, shuffle=False, num_workers=num_workers, pin_memory=True
        )
    elif dataset_name == "cifar100":
        train_loader, test_loader = get_cifar100_loaders(
            root=data_root, batch_size=batch_size, num_workers=num_workers, augment=data_aug
        )
    elif dataset_name == "imagenet32":
        train_loader, test_loader = get_imagenet32_loaders(
            root=data_root, batch_size=batch_size, num_workers=num_workers, augment=data_aug
        )
    else:
        raise ValueError(f"Unknown dataset.name={dataset_name}")

    # 8) í´ë˜ìŠ¤ ìˆ˜
    if isinstance(train_loader.dataset, torch.utils.data.ConcatDataset):
        num_classes = 100
    else:
        n_classes = getattr(train_loader.dataset, "classes", None)
        if n_classes is None:
            n_classes = getattr(train_loader.dataset, "num_classes", None)
        if n_classes is None:
            raise AttributeError("Dataset must expose `classes` or `num_classes`")
        num_classes = len(n_classes) if not isinstance(n_classes, int) else n_classes

    exp_logger.update_metric("num_classes", num_classes)
    check_label_range(train_loader.dataset, num_classes)
    check_label_range(test_loader.dataset, num_classes)

    # 9) êµì‚¬/í•™ìƒ ìƒì„±
    # teacher1
    t1 = exp_dict.get("teacher1", {})
    t1_name = t1.get("name")
    if not t1_name:
        raise ValueError("Missing 'experiment.teacher1.name'")
    t1_ckpt = exp_dict.get("teacher1_ckpt", f"./checkpoints/teachers/{t1_name}_ft.pth")

    logging.getLogger().setLevel(logging.WARNING)
    teacher1 = create_teacher_by_name(
        teacher_name=t1_name,
        num_classes=num_classes,
        pretrained=t1.get("pretrained", True),
        small_input=small_input,
        cfg=exp_dict,
    ).to(device)
    logging.getLogger().setLevel(logging.INFO)

    if os.path.exists(t1_ckpt):
        try:
            sd = torch.load(t1_ckpt, map_location=device, weights_only=True)
        except TypeError:
            sd = torch.load(t1_ckpt, map_location=device)
        teacher1.load_state_dict(sd, strict=False)
        logging.info("Loaded teacher1 from %s", t1_ckpt)

    # teacher2
    t2 = exp_dict.get("teacher2", {})
    t2_name = t2.get("name")
    if not t2_name:
        raise ValueError("Missing 'experiment.teacher2.name'")
    t2_ckpt = exp_dict.get("teacher2_ckpt", f"./checkpoints/teachers/{t2_name}_ft.pth")

    logging.getLogger().setLevel(logging.WARNING)
    teacher2 = create_teacher_by_name(
        teacher_name=t2_name,
        num_classes=num_classes,
        pretrained=t2.get("pretrained", True),
        small_input=small_input,
        cfg=exp_dict,
    ).to(device)
    logging.getLogger().setLevel(logging.INFO)

    if os.path.exists(t2_ckpt):
        try:
            sd = torch.load(t2_ckpt, map_location=device, weights_only=True)
        except TypeError:
            sd = torch.load(t2_ckpt, map_location=device)
        teacher2.load_state_dict(sd, strict=False)
        logging.info("Loaded teacher2 from %s", t2_ckpt)

    # Optional quick eval of teachers
    teacher1_acc = 0.0
    teacher2_acc = 0.0
    if exp_dict.get("compute_teacher_eval", False):
        try:
            teacher1_acc = _quick_eval(teacher1, test_loader, device)
            logging.info("Teacher1 (%s) testAcc=%.2f%%", t1_name, teacher1_acc)
            teacher2_acc = _quick_eval(teacher2, test_loader, device)
            logging.info("Teacher2 (%s) testAcc=%.2f%%", t2_name, teacher2_acc)
        except Exception as e:
            logging.warning("Teacher quick eval failed: %s", e)

    # í•™ìƒ
    s = exp_dict.get("model", {}).get("student", {})
    s_name = s.get("name")
    if not s_name:
        raise ValueError("Missing 'experiment.model.student.name'")

    logging.getLogger().setLevel(logging.WARNING)
    student = create_student_by_name(
        s_name,
        pretrained=s.get("pretrained", False),
        small_input=small_input,
        num_classes=num_classes,
        cfg=exp_dict,
    ).to(device)
    logging.getLogger().setLevel(logging.INFO)

    # 10) í•™ìŠµ ì „ ì„¤ì • (IB_MBM ìƒì„± ì „ì— q_dim ì„¤ì •)
    num_stages = int(exp_dict.get("num_stages", 1))
    setup_partial_freeze_schedule_with_cfg(exp_dict, num_stages)
    setup_safety_switches_with_cfg(exp_dict, num_stages)
    auto_set_ib_mbm_query_dim_with_model(student, exp_dict)  # â† IB_MBM ìƒì„± ì „ì— í˜¸ì¶œ
    renorm_ce_kd(exp_dict)

    # 11) IB_MBM & Synergy Head (q_dim ì„¤ì • í›„ ìƒì„±)
    from models import build_ib_mbm_from_teachers as build_from_teachers
    ib_mbm, synergy_head = build_from_teachers([teacher1, teacher2], exp_dict)
    ib_mbm = ib_mbm.to(device)
    synergy_head = synergy_head.to(device)
    
    # 11-a) ì±„ë„-ë¼ìŠ¤íŠ¸ ë©”ëª¨ë¦¬ í¬ë§· ì ìš© (Conv ì—°ì‚° ê°€ì†)
    if device == "cuda" and torch.cuda.is_available():
        # ConvNet ê³„ì—´ ëª¨ë¸ë“¤ì„ ì±„ë„-ë¼ìŠ¤íŠ¸ í¬ë§·ìœ¼ë¡œ ë³€í™˜
        for model, name in [(teacher1, "teacher1"), (teacher2, "teacher2"), (student, "student")]:
            try:
                model = model.to(memory_format=torch.channels_last)
                logger.info(f"{name} converted to channels_last memory format")
            except Exception as e:
                logger.debug(f"Could not convert {name} to channels_last: {e}")
        # IB_MBMê³¼ synergy_headëŠ” ì£¼ë¡œ Linear ë ˆì´ì–´ì´ë¯€ë¡œ ì œì™¸

    # 11-b) ë©”íƒ€ë°ì´í„° ë°°ë„ˆ ë° ì €ì¥
    try:
        # teacher1/2 accê°€ ë³„ë„ ì¸¡ì •ë˜ì§€ ì•Šì•˜ë‹¤ë©´ 0.0ìœ¼ë¡œ
        _log_and_save_meta(
            logger,
            exp_logger,
            exp_dict,
            t1_name=t1_name,
            t2_name=t2_name,
            s_name=s_name,
            t1_acc=locals().get("teacher1_acc", 0.0),
            t2_acc=locals().get("teacher2_acc", 0.0),
        )
    except Exception as _e:
        logger.warning("[META] banner/meta save skipped: %s", _e)

    # 12) ë¡œê·¸
    logging.info("ğŸš€ Starting training process...")
    logging.info(f"CL mode: {exp_dict.get('cl_mode', False)}")
    logging.info(f"Number of stages: {num_stages}")
    logging.info(f"Student epochs per stage: {exp_dict.get('student_epochs_per_stage', [])}")
    logging.info(f"Batch size: {batch_size}")
    logging.info(f"Device: {device}")
    logging.info(f"Train loader size: {len(train_loader)} batches")
    logging.info(f"Test loader size: {len(test_loader)} batches")
    logging.info(f"Dataset classes: {num_classes}")

    # 13) íŠ¸ë ˆì´ë‹
    if exp_dict.get("cl_mode", False):
        logging.info("ğŸ“š Running in Continual Learning mode...")
        final_acc = run_continual_learning(
            [teacher1, teacher2], ib_mbm, synergy_head, student, exp_dict, exp_logger
        )
    else:
        logging.info("ğŸ¯ Running in Standard training mode...")
        try:
            logging.info("ğŸ“Š Training will start now - you should see epoch progress logs...")
            final_acc = run_training_stages(
                [teacher1, teacher2],
                ib_mbm,
                synergy_head,
                student,
                train_loader,
                test_loader,
                exp_dict,
                exp_logger,
                num_stages,
            )
            logging.info(f"âœ… run_training_stages completed with accuracy: {final_acc:.2f}%")
        except Exception as e:
            logging.error(f"âŒ run_training_stages failed: {e}", exc_info=True)
            final_acc = 0.0

    logging.info(f"âœ… Training completed. Final student accuracy: {final_acc:.2f}%")
    exp_logger.update_metric("final_student_acc", final_acc)
    exp_logger.save_results()
    return final_acc


if __name__ == "__main__":
    main() 