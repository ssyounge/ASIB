# configs/finetune/convnext_l_cifar32.yaml

# ConvNeXt‑L 파인튜닝 (CIFAR‑100, 32×32 입력)
# @package _global_
defaults:
  - /dataset: cifar100
  - _self_

teacher_type:  convnext_l
small_input:   true
teacher_pretrained:  true
teacher_ckpt_init:   null                 # 이어서 학습할 ckpt 경로가 있으면 지정

# ─── 옵티마이저 & 학습 하이퍼파라미터 ──────────────────────────
finetune_epochs:        30        # 30 epoch이면 충분히 수렴 (32×32 데이터셋)
finetune_lr:            5e-4      # AdamW + cosine
finetune_weight_decay:  5e-2
warmup_epochs:          3
min_lr:                 1e-6
batch_size:             64        # 3090 GPU에서 여유
label_smoothing:        0.1
finetune_use_cutmix:    true
finetune_cutmix_alpha:  1.0

# ─── 출력 경로 ────────────────────────────────────────────────
results_dir:        outputs/convnext_l_cifar32_ft
exp_id:             convnext_l_cifar32
# ─── 공통 옵션 (AMP 등) ───────────────────────────────────────
use_amp:    true
device:     cuda
seed:       42
log_level:  INFO
deterministic: true

# 추후 save 할 체크포인트 경로
finetune_ckpt_path: checkpoints/convnext_l_cifar32.pth

# Hydra 의 편의를 위해 명시(로더에서 사용)
dataset_name: cifar100
data_root:    ./data

