# configs/default.yaml

device: "cuda"          # "cuda" or "cpu"
seed: 42
dataset_name: "cifar100"
small_input: true
data_root: "./data"
batch_size: 128

teacher1_type: "resnet101"
teacher2_type: "efficientnet_b2"

teacher1_pretrained: true
teacher2_pretrained: true

teacher_lr: 0.0001           # 통합 Teacher 학습률
teacher_weight_decay: 0.0003
teacher_adapt_epochs: 5      # Teacher Adaptive Update epochs
mbm_lr_factor: 5.0           # MBM/Head LR 배수

synergy_ce_alpha: 0.3
teacher_adapt_alpha_kd: 0.2  # Teacher adaptive 시 KL 비중

reg_lambda: 1e-5   # Teacher param reg

student_type: "efficientnet_adapter"
student_lr: 0.01
student_weight_decay: 0.0005
student_epochs_per_stage: 15  # Student distill epochs per stage

ce_alpha: 0.5     # CE 비중
kd_alpha: 0.5     # KL 비중
temperature: 4.0

num_stages: 2

teacher_iters: 10
student_iters: 20

use_partial_freeze: true

mbm_in_dim: 3456
mbm_hidden_dim: 1024
mbm_out_dim: 2048
mbm_dropout: 0.0
synergy_head_dropout: 0.0
mbm_use_4d: false
mbm_attn_heads: 0

cutmix_alpha: 1.0
mixup_alpha: 0.0
label_smoothing: 0.0

log_filename: "train.log"
save_checkpoint: true
ckpt_dir: "./checkpoints"

# Optional teacher fine-tuning before ASMB stages
finetune_epochs: 0           # >0 => run fine-tuning step
finetune_lr: 0.001
finetune_weight_decay: 0.0005
finetune_use_cutmix: true
finetune_alpha: 1.0
finetune_ckpt1: "./checkpoints/teacher1_finetuned.pth"
finetune_ckpt2: "./checkpoints/teacher2_finetuned.pth"
