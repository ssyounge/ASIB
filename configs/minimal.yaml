# configs/minimal.yaml

batch_size: 128              # â†‘ ê°€ëŠ¥í•˜ë©´ 256 (GPU ì—¬ìœ  ì‹œ)
num_workers: 2
disable_tqdm: true
dataset_root: "./data"
results_dir: "results"
device: "cuda"
seed: 42
checkpoint_dir: "checkpoints"

student_type: "convnext_tiny"

# â”€ IBâ€‘KD í•˜ì´í¼ â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
mbm_type: "VIB"
z_dim: 256

beta_bottleneck: 0.003       # IBÂ KLÂ ê°€ì¤‘ì¹˜
alpha_kd: 0.7                # softâ€‘KD ë¹„ì¤‘ â†‘
kd_alpha_init: 0.7          # KD ì´ˆë°˜ ê°€ì¤‘ì¹˜
kd_alpha_final: 0.3         # KD í›„ë°˜ ê°€ì¤‘ì¹˜
kd_T_init: 4                # ì´ˆê¸° ì˜¨ë„
kd_T_final: 3               # ìµœì¢… ì˜¨ë„
kd_warmup_frac: 0.0         # ì•ë¶€ë¶„ ìŠ¤ì¼€ì¤„ ê³ ì • ë¹„ìœ¨
kd_schedule_granularity: step
ce_alpha: 1.0                # ğŸ”¸ CEÂ ê·¸ëŒ€ë¡œ
kd_temperature: 3            # ğŸ”¹ ìƒˆ í•­ëª© â€‘Â T
latent_alpha: 0.3            # zâ€‘MSE ë¹„ì¤‘ â†“
label_smoothing: 0.1         # ğŸ”¹ CEÂ ì•ˆì •í™”
randaug_N: 2                 # ğŸ”¹ RandAug(N,M)
randaug_M: 7
 
teacher_weight_decay: 5e-4
student_weight_decay: 5e-4
teacher_lr: 3e-4
student_lr: 6e-4
lr_schedule: "cosine"
grad_clip_norm: 1.0

# run evaluation after training loop by default
eval_after_train: true

# â”€ DataÂ Mixing â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
mixup_alpha: 0.1             # CutMixÂ ëŒ€ì‹  MixUpÂ ê²½ëŸ‰ ì‚¬ìš©
cutmix_alpha_distill: 0.0    # (0Â =Â MixUpÂ ìš°ì„ )
 
# â”€ í•™ìŠµ ìŠ¤í…Œì´ì§€ â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

teacher_iters: 12            # êµì‚¬ ì¶”ê°€ ì ì‘
student_iters: 40            # í•™ìƒ í•™ìŠµ 2Ã—

# â”€ EMA í‰ê°€ â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
use_ema: true
ema_decay: 0.998

# --- Teacher fineâ€‘tune ---
finetune_epochs: 20
finetune_lr: 5e-4
finetune_weight_decay: 1e-5
teacher2_freeze_scope: "none"
