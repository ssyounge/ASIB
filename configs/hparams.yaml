# configs/hparams.yaml
# Common hyperparameters for ASMB experiments.
# Edit these values and run the bash scripts.

# General
device: "cuda"
batch_size: 128
seed: 42
data_aug: 1
dataset_name: "cifar100"
small_input: true
deterministic: true

# Teacher defaults
teacher_type: "resnet101"
finetune_partial_freeze: false
efficientnet_dropout: 0.3

# Teacher fine-tuning
finetune_epochs: 50
finetune_lr: 0.001
finetune_weight_decay: 0.0005
finetune_cutmix_alpha: 1.0

# Distillation
method: "asmb"
teacher_lr: 1e-4
student_lr: 3e-4
teacher_weight_decay: 0.0003
student_weight_decay: 0.0005
ce_alpha: 0.5
kd_alpha: 0.5
cutmix_alpha_distill: 0.0  # CutMix alpha used during distillation

# Learning rate schedule
lr_schedule: "cosine"       # "step" or "cosine"
teacher_step_size: 10
teacher_gamma: 0.1
student_step_size: 10
student_gamma: 0.1

# Temperature scheduling
temperature_schedule: "linear_decay"
tau_start: 10.0
tau_end: 2.0
tau_decay_epochs: 40
student_eps: 10
teacher_iters: 20
student_iters: 40
mbm_hidden_dim: 1024
mbm_out_dim: 2048
mbm_reg: 5e-5         # default sweep value
reg_lambda: 1e-5      # teacher L2 regularisation
mbm_dropout: 0.0      # dropout prob inside MBM
head_dropout: 0.0     # dropout prob for synergy head
use_partial_freeze: true
# freeze_level guide: 0=head only, 1=last block+head, 2=two blocks+head
student_freeze_level: 2  # 0: head only, 1: last block + head, 2: last 2 blocks + head
student_use_adapter: true
student_freeze_bn: false
teacher1_use_adapter: 0
teacher1_bn_head_only: 0
teacher2_use_adapter: 0
teacher2_bn_head_only: 0
mixup_alpha: 0.0
label_smoothing: 0.0

# Sweep/loop variables
# N_STAGE_LIST accepts a space-separated list of stage counts,
# e.g. "2 3 4 5" to run multiple values in a batch script.
n_stage_list: 5
sc_alpha_list: "0.6" # 0.3 0.6
student_list: "resnet_adapter efficientnet_adapter swin_adapter"
method_list: "asmb vanilla_kd" ## asmb at crd dkd fitnet
# Teacher adaptation
teacher_adapt_epochs: 5
teacher_adapt_alpha_kd: 1.0
mbm_lr_factor: 1.0
synergy_ce_alpha: 0.3

# Feature KD
feat_kd_alpha: 1.0
feat_kd_key: "feat_2d"
feat_kd_norm: "none"

# Disagreement weighting
use_disagree_weight: false
disagree_mode: "pred"
disagree_lambda_high: 1.0
disagree_lambda_low: 1.0

# MBM options
mbm_type: "LA"
mbm_r: 4
mbm_n_head: 1
mbm_learnable_q: true
mbm_in_dim: 3456
mbm_use_4d: false
mbm_attn_heads: 0
mbm_query_dim: 0

# Misc
grad_clip_norm: 1.0
finetune_use_cutmix: true
finetune_alpha: 1.0
