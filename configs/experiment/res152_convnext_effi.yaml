# configs/experiment/res152_convnext_effi.yaml
defaults:
  - /base
  - /model/teacher@teacher1: convnext_l        # Teacher‑1 → ConvNeXt‑L
  - /model/teacher@teacher2: efficientnet_l2   # Teacher‑2 → EffNet‑L2
  - /model/student:          resnet152_pretrain
  - _self_

# ─── 경로 & 식별자 ────────────────────────────────────────────
teacher1_ckpt: checkpoints/convnext_l_cifar32.pth   # ← fc 5504▶100 형상 맞춰 trim
teacher2_ckpt: checkpoints/efficientnet_l2_cifar32.pth
results_dir:   outputs/res152_convnext_effi
exp_id:        res152_convnext_effi

# ─── 모델 & Optim ────────────────────────────────────────────
teacher_lr:            5.0e-5     # ↓ 더 보수적으로 (teacher 안정화)
teacher_weight_decay:  1.0e-4     # ↑ 원래대로
student_lr:            2.0e-4     # ↓ 더 보수적으로 (student 안정화)
student_weight_decay:  3.0e-4     # ↑ 원래대로

# ─── Partial‑Freeze Stage 스케줄 ──────────────────────────────
use_partial_freeze: true
num_stages: 4
teacher_adapt_epochs: 1          # ↓ 3→1로 줄임
student_freeze_schedule:  [-1, 2, 1, 0]
student_epochs_schedule:  [15, 15, 15, 15]  # ↑ 더 길게 (안정화)
teacher1_freeze_level: 1         # layer‑4 only
teacher2_freeze_level: 1
student_freeze_bn:     false
teacher1_freeze_bn:    true
teacher2_freeze_bn:    true

# ─── MBM / Adapter ───────────────────────────────────────────
use_distillation_adapter: true
distill_out_dim: 512        # Key 채널 수
mbm_query_dim:   2048       # 학생 feat_2d
mbm_out_dim:     2048       # == query_dim (truncation 방지)
mbm_n_head:      8          # 2048 ÷ 8 = 256 channels
use_ib:          true
ib_beta:         0.0005     # ↓ 더 보수적으로 (IB 안정화)
ib_beta_warmup_epochs: 5    # ↑ 더 길게 (IB 안정화)
mbm_reg_lambda: 0.0         # ↓ L2 reg 제거

# ─── KD 세부 옵션 (Ensemble + Disagree) ──────────────────────
kd_alpha:            0.1    # ↓ 더 보수적으로
kd_ens_alpha:        0.5    # ↓ 더 보수적으로
use_disagree_weight: false  # ← 일단 끔 (disagreement 문제 해결)
disagree_mode:       both_wrong
disagree_lambda_high: 1.2   # ↓ 더 보수적으로
disagree_lambda_low:  0.8   # ↓ 더 보수적으로

# ─── CCCP (Concave-Convex Procedure) ─────────────────────────
use_cccp:            false    # ↓ 일단 끔
tau:                 4.0      # KL temperature (KD & CCCP 동일)

# ─── 데이터증강 / 기타 ───────────────────────────────────────────
batch_size: 48                  # ↓ 더 작게
cutmix_alpha_distill: 0.0      # ↓ 일단 끔
mixup_alpha: 0.0               # ↓ 일단 끔
grad_clip_norm: 1.0            # ↓ 더 보수적으로
