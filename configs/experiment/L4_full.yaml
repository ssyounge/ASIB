defaults:
  - /base
  - /model/teacher@experiment.teacher1: convnext_l
  - /model/teacher@experiment.teacher2: resnet152
  - /model/student@experiment.model.student: resnet101_scratch
  - _self_

experiment:
  exp_id: L4_full
  results_dir: experiments/ablation/L4/results
  teacher1_ckpt: checkpoints/teachers/convnext_l_cifar100.pth
  teacher2_ckpt: checkpoints/teachers/resnet152_cifar100.pth

  dataset: { batch_size: 64, num_workers: 8, data_aug: 1, pin_memory: true, persistent_workers: true, prefetch_factor: 2 }

  num_stages: 4
  student_epochs_per_stage: [20, 20, 20, 20]
  teacher_adapt_epochs: 4
  compute_teacher_eval: true

  use_amp: true
  amp_dtype: bfloat16

  # KD (auto_min + two_view + centering)
  kd_target: auto_min
  kd_auto_policy: label_ce
  kd_target_mode: two_view
  kd_center_teacher: true
  teacher_adapt_kd_warmup: 0
  kd_ens_alpha: 0.0
  enable_kd_after_syn_acc: 0.65
  ce_alpha: 0.65
  kd_alpha: 0.35
  tau: 4.0
  kd_warmup_epochs: 3
  kd_max_ratio: 1.25
  ce_label_smoothing: 0.05
  feat_kd_alpha: 0.25
  min_cw: 0.5
  max_cw: 1.5

  # IB
  use_ib: true
  ib_epochs_per_stage: 6
  ib_beta: 5e-05
  ib_beta_warmup_epochs: 4
  ib_mbm_query_dim: 512
  ib_mbm_out_dim: 512
  ib_mbm_n_head: 4
  ib_mbm_feature_norm: l2
  ib_mbm_logvar_clip: 4
  ib_mbm_min_std: 0.01
  ib_mbm_lr_factor: 2

  # CCCP
  use_cccp: true
  use_cccp_in_a: true
  cccp_alpha: 0.20
  tau: 4.0

  # Teacher Adapt(어댑터만)
  use_teacher_finetuning: false
  train_distill_adapter_only: true
  teacher_lr: 3e-06
  teacher_weight_decay: 1e-4

  # PPF(부분 동결) – 안정/속도/VRAM 절감
  use_partial_freeze: true
  student_freeze_level_schedule: [-1, -1, 1, 1]
  teacher1_freeze_level_schedule: [-1, -1, 1, 1]
  teacher2_freeze_level_schedule: [-1, -1, 1, 1]
  student_freeze_bn: true
  teacher1_freeze_bn: true
  teacher2_freeze_bn: true

  # A‑Step 안정화
  synergy_only_epochs: 2
  synergy_ce_alpha: 1.0
  disable_loss_clamp_in_a: true

  use_distillation_adapter: true
  distill_out_dim: 512
  feat_kd_key: distill_feat

  optimizer: adamw
  student_lr: 0.001
  student_weight_decay: 0.0003
  a_step_lr: 0.0001
  a_step_weight_decay: 0.0001
  grad_clip_norm: 0.5
  use_loss_clamp: true
  loss_clamp_mode: soft
  loss_clamp_max: 20.0
  loss_clamp_warmup_epochs: 8
  schedule: { type: cosine, lr_warmup_epochs: 5, min_lr: 1e-6 }
  mixup_alpha: 0.2
  cutmix_alpha_distill: 1.0

  # Full spec extras (EMA, uncertainty, cooldown, teacher2 decay)
  use_ema_teacher: true
  ema_decay: 0.999
  ema_update_every: 1
  kd_uncertainty_weight: 0.5
  kd_uncertainty_min: 0.2
  kd_correct_min: 0.2
  kd_cooldown_epochs: 10
  teacher2_weight_decay_start_epoch: 30
  teacher2_weight_decay_len: 10
  synergy_temp_learnable: true
  synergy_logit_scale: 1.0
  tau_syn: 4.0
  synergy_probe_every: 10


