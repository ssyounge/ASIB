#!/usr/bin/env python3
"""
Sensitivity Analysis for ASIB-KD Framework

Phase 1: êµ¬ì„± ìš”ì†Œ ë¶„ì„ (Ablation Study)
ëª©í‘œ: ASIBë¥¼ êµ¬ì„±í•˜ëŠ” í•µì‹¬ ìš”ì†Œë“¤(IB, CCCP, Teacher Adaptation, PF)ì´ ìµœì¢… ì„±ëŠ¥ í–¥ìƒì— ë…ë¦½ì ìœ¼ë¡œ ê¸°ì—¬í•¨ì„ ì¦ëª…

ê³ ì • í™˜ê²½:
- ë°ì´í„°ì…‹: CIFAR-100
- Teachers (ì´ì¢… êµ¬ì¡°): ConvNeXt-S + ResNet152
- Student: ResNet50

ì‹¤í—˜ êµ¬ì„±:
1. Baseline ì„¤ì • (MBM + E2E + Fixed Teachers)
2. Information Bottleneck (IB) íš¨ê³¼ ê²€ì¦ (+IB)
3. CCCP (Stage-wise í•™ìŠµ) íš¨ê³¼ ê²€ì¦ (+IB +CCCP)
4. Teacher Adaptation íš¨ê³¼ ê²€ì¦ (+IB +CCCP +T-Adapt)
5. Progressive Partial Freezing (PF) íš¨ê³¼ ê²€ì¦ (ASIB Full)

ì¤‘ìš” ë¶„ì„: CCCP ì ìš© ì‹œ ë” ë¹ ë¥´ê³  ì•ˆì •ì ìœ¼ë¡œ(ì§„ë™ ì—†ì´) ìˆ˜ë ´í•¨ì„ ë³´ì´ëŠ” ê²ƒì´ í•µì‹¬ì…ë‹ˆë‹¤.
"""

import os
import sys
import logging
import numpy as np
import torch
import torch.nn as nn
from pathlib import Path
from typing import Dict, List, Tuple, Optional
import matplotlib.pyplot as plt
import seaborn as sns
from dataclasses import dataclass
import json

# Add project root to path
sys.path.append(str(Path(__file__).parent.parent.parent))

from core.builder import create_teacher_by_name, create_student_by_name
from data.cifar100 import get_cifar100_loaders
from utils.logging import setup_logging


@dataclass
class AblationConfig:
    """Ablation ì‹¤í—˜ ì„¤ì •"""
    experiment_name: str
    use_ib: bool = False
    use_cccp: bool = False
    use_teacher_adaptation: bool = False
    use_pf: bool = False
    beta: float = 0.001  # VIB íŒŒë¼ë¯¸í„°
    description: str = ""


def create_ablation_configs() -> List[AblationConfig]:
    """Ablation ì‹¤í—˜ ì„¤ì •ë“¤ ìƒì„±"""
    configs = []
    
    # ì‹¤í—˜ 1: Baseline ì„¤ì • (MBM + E2E + Fixed Teachers)
    configs.append(AblationConfig(
        experiment_name="baseline",
        use_ib=False,
        use_cccp=False,
        use_teacher_adaptation=False,
        use_pf=False,
        description="MBM + E2E + Fixed Teachers"
    ))
    
    # ì‹¤í—˜ 2: Information Bottleneck (IB) íš¨ê³¼ ê²€ì¦ (+IB)
    configs.append(AblationConfig(
        experiment_name="baseline_plus_ib",
        use_ib=True,
        use_cccp=False,
        use_teacher_adaptation=False,
        use_pf=False,
        description="Baseline + Information Bottleneck"
    ))
    
    # ì‹¤í—˜ 3: CCCP (Stage-wise í•™ìŠµ) íš¨ê³¼ ê²€ì¦ (+IB +CCCP)
    configs.append(AblationConfig(
        experiment_name="baseline_plus_ib_cccp",
        use_ib=True,
        use_cccp=True,
        use_teacher_adaptation=False,
        use_pf=False,
        description="Baseline + IB + CCCP"
    ))
    
    # ì‹¤í—˜ 4: Teacher Adaptation íš¨ê³¼ ê²€ì¦ (+IB +CCCP +T-Adapt)
    configs.append(AblationConfig(
        experiment_name="baseline_plus_ib_cccp_tadapt",
        use_ib=True,
        use_cccp=True,
        use_teacher_adaptation=True,
        use_pf=False,
        description="Baseline + IB + CCCP + Teacher Adaptation"
    ))
    
    # ì‹¤í—˜ 5: Progressive Partial Freezing (PF) íš¨ê³¼ ê²€ì¦ (ASIB Full)
    configs.append(AblationConfig(
        experiment_name="asib_full",
        use_ib=True,
        use_cccp=True,
        use_teacher_adaptation=True,
        use_pf=True,
        description="ASIB Full (Baseline + IB + CCCP + T-Adapt + PF)"
    ))
    
    return configs


def run_ablation_experiment(config: AblationConfig, seed: int = 42) -> Dict[str, float]:
    """
    íŠ¹ì • Ablation ì„¤ì •ì—ì„œ ì‹¤í—˜ ì‹¤í–‰
    
    Args:
        config: Ablation ì„¤ì •
        seed: ëœë¤ ì‹œë“œ
    
    Returns:
        ì‹¤í—˜ ê²°ê³¼ ë”•ì…”ë„ˆë¦¬
    """
    # ì‹œë“œ ì„¤ì •
    torch.manual_seed(seed)
    np.random.seed(seed)
    
    device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
    
    # êµì‚¬ ëª¨ë¸ë“¤ ìƒì„±
    teacher1 = create_teacher_by_name("convnext_s_teacher", pretrained=True)
    teacher2 = create_teacher_by_name("resnet152_teacher", pretrained=True)
    
    teacher1 = teacher1.to(device)
    teacher2 = teacher2.to(device)
    
    # í•™ìƒ ëª¨ë¸ ìƒì„±
    student = create_student_by_name("resnet50_student", pretrained=False)
    student = student.to(device)
    
    # ë°ì´í„° ë¡œë”
    train_loader, val_loader = get_cifar100_loaders(
        root="./data",
        batch_size=128,
        num_workers=4
    )
    
    # í•™ìŠµ ì„¤ì •
    criterion = nn.CrossEntropyLoss()
    optimizer = torch.optim.SGD(student.parameters(), lr=0.1, momentum=0.9, nesterov=True)
    scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=200)
    
    # í•™ìŠµ ê¸°ë¡
    train_losses = []
    val_losses = []
    train_accuracies = []
    val_accuracies = []
    
    # í•™ìŠµ
    num_epochs = 200
    best_acc = 0.0
    
    for epoch in range(num_epochs):
        student.train()
        train_loss = 0.0
        train_correct = 0
        train_total = 0
        
        for batch_idx, (data, target) in enumerate(train_loader):
            data, target = data.to(device), target.to(device)
            
            optimizer.zero_grad()
            
            # í•™ìƒ ëª¨ë¸ ì¶œë ¥
            student_output = student(data)
            
            # êµì‚¬ ëª¨ë¸ë“¤ ì¶œë ¥
            with torch.no_grad():
                teacher1_output = teacher1(data)
                teacher2_output = teacher2(data)
            
            # ê¸°ë³¸ ì†ì‹¤
            loss = criterion(student_output, target)
            
            # IB ì ìš© (ì‹¤í—˜ 2, 3, 4, 5)
            if config.use_ib:
                # VIB ì†ì‹¤ ê³„ì‚° (ê°„ë‹¨í•œ ë²„ì „)
                kl_loss = torch.mean(torch.sum(student_output * torch.log(student_output + 1e-8), dim=1))
                loss += config.beta * kl_loss
            
            # CCCP ì ìš© (ì‹¤í—˜ 3, 4, 5)
            if config.use_cccp:
                # A-Step: IB-MBM í•™ìŠµ
                if epoch % 2 == 0:  # A-Step
                    pass  # IB-MBM í•™ìŠµ ë¡œì§
                # B-Step: Student í•™ìŠµ
                else:  # B-Step
                    pass  # Student í•™ìŠµ ë¡œì§
            
            # Teacher Adaptation ì ìš© (ì‹¤í—˜ 4, 5)
            if config.use_teacher_adaptation:
                # êµì‚¬ ëª¨ë¸ ìƒìœ„ ë ˆì´ì–´ ì—…ë°ì´íŠ¸
                teacher_adaptation_loss = 0.1 * (nn.MSELoss()(student_output, teacher1_output) + 
                                                nn.MSELoss()(student_output, teacher2_output))
                loss += teacher_adaptation_loss
            
            # PF ì ìš© (ì‹¤í—˜ 5)
            if config.use_pf:
                # Progressive Partial Freezing ë¡œì§
                if epoch < 50:
                    # ì´ˆê¸° 50 ì—í¬í¬: ëª¨ë“  ë ˆì´ì–´ í•™ìŠµ
                    pass
                elif epoch < 100:
                    # 50-100 ì—í¬í¬: ì¼ë¶€ ë ˆì´ì–´ ê³ ì •
                    pass
                else:
                    # 100+ ì—í¬í¬: ë” ë§ì€ ë ˆì´ì–´ ê³ ì •
                    pass
            
            loss.backward()
            optimizer.step()
            
            train_loss += loss.item()
            _, predicted = student_output.max(1)
            train_total += target.size(0)
            train_correct += predicted.eq(target).sum().item()
        
        # Validation
        student.eval()
        val_loss = 0.0
        val_correct = 0
        val_total = 0
        
        with torch.no_grad():
            for data, target in val_loader:
                data, target = data.to(device), target.to(device)
                output = student(data)
                loss = criterion(output, target)
                
                val_loss += loss.item()
                _, predicted = output.max(1)
                val_total += target.size(0)
                val_correct += predicted.eq(target).sum().item()
        
        # ë©”íŠ¸ë¦­ ê³„ì‚°
        train_acc = 100. * train_correct / train_total
        val_acc = 100. * val_correct / val_total
        
        train_losses.append(train_loss / len(train_loader))
        val_losses.append(val_loss / len(val_loader))
        train_accuracies.append(train_acc)
        val_accuracies.append(val_acc)
        
        if val_acc > best_acc:
            best_acc = val_acc
        
        scheduler.step()
        
        if (epoch + 1) % 50 == 0:
            print(f'Epoch {epoch+1}/{num_epochs}: Train Acc: {train_acc:.2f}%, Val Acc: {val_acc:.2f}%')
    
    return {
        "experiment_name": config.experiment_name,
        "description": config.description,
        "use_ib": config.use_ib,
        "use_cccp": config.use_cccp,
        "use_teacher_adaptation": config.use_teacher_adaptation,
        "use_pf": config.use_pf,
        "beta": config.beta,
        "best_accuracy": best_acc,
        "final_train_accuracy": train_accuracies[-1],
        "final_val_accuracy": val_accuracies[-1],
        "train_losses": train_losses,
        "val_losses": val_losses,
        "train_accuracies": train_accuracies,
        "val_accuracies": val_accuracies
    }


def run_sensitivity_analysis():
    """Sensitivity Analysis ë©”ì¸ í•¨ìˆ˜"""
    logger = setup_logging({
        "results_dir": "outputs/analysis/sensitivity_analysis",
        "exp_id": "sensitivity_analysis",
        "log_level": "INFO"
    })
    
    logger.info("ğŸš€ Starting Sensitivity Analysis (Ablation Study)")
    logger.info("=" * 60)
    
    # Ablation ì„¤ì •ë“¤ ìƒì„±
    ablation_configs = create_ablation_configs()
    logger.info(f"Created {len(ablation_configs)} ablation configurations")
    
    # ê²°ê³¼ ì €ì¥
    results = []
    
    # ê° ì‹¤í—˜ ì‹¤í–‰ (3íšŒ ë°˜ë³µ)
    for i, config in enumerate(ablation_configs):
        logger.info(f"Experiment {i+1}/{len(ablation_configs)}: {config.experiment_name}")
        logger.info(f"Description: {config.description}")
        logger.info(f"IB: {config.use_ib}, CCCP: {config.use_cccp}, T-Adapt: {config.use_teacher_adaptation}, PF: {config.use_pf}")
        
        # 3íšŒ ë°˜ë³µ ì‹¤í—˜
        experiment_results = []
        for run in range(3):
            logger.info(f"  Run {run+1}/3")
            result = run_ablation_experiment(config, seed=42+run)
            experiment_results.append(result)
        
        # í‰ê·  ë° í‘œì¤€í¸ì°¨ ê³„ì‚°
        accuracies = [r['best_accuracy'] for r in experiment_results]
        mean_acc = np.mean(accuracies)
        std_acc = np.std(accuracies)
        
        # ìµœì¢… ê²°ê³¼ ì €ì¥
        final_result = {
            "experiment_name": config.experiment_name,
            "description": config.description,
            "use_ib": config.use_ib,
            "use_cccp": config.use_cccp,
            "use_teacher_adaptation": config.use_teacher_adaptation,
            "use_pf": config.use_pf,
            "beta": config.beta,
            "mean_accuracy": mean_acc,
            "std_accuracy": std_acc,
            "individual_results": experiment_results
        }
        
        results.append(final_result)
        
        logger.info(f"  Mean Accuracy: {mean_acc:.2f}% Â± {std_acc:.2f}%")
        logger.info("-" * 40)
    
    # ê²°ê³¼ ì‹œê°í™”
    plot_sensitivity_results(results)
    
    # ê²°ê³¼ ì €ì¥
    save_sensitivity_results(results)
    
    logger.info("âœ… Sensitivity Analysis completed!")
    
    return results


def plot_sensitivity_results(results: List[Dict[str, float]]):
    """Sensitivity Analysis ê²°ê³¼ ì‹œê°í™”"""
    # ë°ì´í„° ì¤€ë¹„
    experiment_names = [r['experiment_name'] for r in results]
    mean_accuracies = [r['mean_accuracy'] for r in results]
    std_accuracies = [r['std_accuracy'] for r in results]
    
    # ê·¸ë˜í”„ ìƒì„±
    plt.figure(figsize=(15, 10))
    
    # 1. ì •í™•ë„ ë¹„êµ
    plt.subplot(2, 3, 1)
    bars = plt.bar(experiment_names, mean_accuracies, yerr=std_accuracies, 
                   capsize=5, alpha=0.7, color='skyblue')
    plt.xlabel('Experiment')
    plt.ylabel('Accuracy (%)')
    plt.title('Ablation Study Results')
    plt.xticks(rotation=45, ha='right')
    plt.grid(True, alpha=0.3)
    
    # 2. êµ¬ì„± ìš”ì†Œë³„ ê¸°ì—¬ë„
    plt.subplot(2, 3, 2)
    components = ['IB', 'CCCP', 'T-Adapt', 'PF']
    contributions = []
    
    baseline_acc = mean_accuracies[0]  # baseline
    
    for i, result in enumerate(results[1:], 1):
        contribution = result['mean_accuracy'] - baseline_acc
        contributions.append(contribution)
    
    plt.bar(components, contributions, color=['green', 'orange', 'red', 'purple'], alpha=0.7)
    plt.xlabel('Component')
    plt.ylabel('Accuracy Improvement (%)')
    plt.title('Component Contributions')
    plt.grid(True, alpha=0.3)
    
    # 3. í•™ìŠµ ê³¡ì„  ë¹„êµ (CCCP íš¨ê³¼)
    plt.subplot(2, 3, 3)
    for i, result in enumerate(results):
        if result['use_ib'] and not result['use_cccp']:  # IBë§Œ
            val_accs = result['individual_results'][0]['val_accuracies']
            plt.plot(val_accs, label='IB Only', linewidth=2)
        elif result['use_ib'] and result['use_cccp']:  # IB + CCCP
            val_accs = result['individual_results'][0]['val_accuracies']
            plt.plot(val_accs, label='IB + CCCP', linewidth=2)
    
    plt.xlabel('Epoch')
    plt.ylabel('Validation Accuracy (%)')
    plt.title('CCCP Effect (Learning Stability)')
    plt.legend()
    plt.grid(True, alpha=0.3)
    
    # 4. ì‹¤í—˜ë³„ ìƒì„¸ ë¹„êµ
    plt.subplot(2, 3, 4)
    x_pos = np.arange(len(experiment_names))
    plt.bar(x_pos, mean_accuracies, yerr=std_accuracies, capsize=5, alpha=0.7)
    plt.xlabel('Experiment')
    plt.ylabel('Accuracy (%)')
    plt.title('Detailed Comparison')
    plt.xticks(x_pos, experiment_names, rotation=45, ha='right')
    plt.grid(True, alpha=0.3)
    
    # 5. êµ¬ì„± ìš”ì†Œ ì¡°í•©ë³„ ì„±ëŠ¥
    plt.subplot(2, 3, 5)
    combinations = []
    accuracies = []
    
    for result in results:
        combo = []
        if result['use_ib']: combo.append('IB')
        if result['use_cccp']: combo.append('CCCP')
        if result['use_teacher_adaptation']: combo.append('T-Adapt')
        if result['use_pf']: combo.append('PF')
        
        combinations.append('+'.join(combo) if combo else 'Baseline')
        accuracies.append(result['mean_accuracy'])
    
    plt.bar(combinations, accuracies, alpha=0.7, color='lightcoral')
    plt.xlabel('Component Combination')
    plt.ylabel('Accuracy (%)')
    plt.title('Component Combination Performance')
    plt.xticks(rotation=45, ha='right')
    plt.grid(True, alpha=0.3)
    
    # 6. í‘œì¤€í¸ì°¨ ë¹„êµ (ì•ˆì •ì„±)
    plt.subplot(2, 3, 6)
    plt.bar(experiment_names, std_accuracies, alpha=0.7, color='lightgreen')
    plt.xlabel('Experiment')
    plt.ylabel('Standard Deviation (%)')
    plt.title('Training Stability')
    plt.xticks(rotation=45, ha='right')
    plt.grid(True, alpha=0.3)
    
    plt.tight_layout()
    plt.savefig('outputs/analysis/sensitivity_analysis/sensitivity_results.png', dpi=300, bbox_inches='tight')
    plt.show()


def save_sensitivity_results(results: List[Dict[str, float]]):
    """ê²°ê³¼ë¥¼ JSON íŒŒì¼ë¡œ ì €ì¥"""
    output_file = 'outputs/analysis/sensitivity_analysis/sensitivity_results.json'
    os.makedirs(os.path.dirname(output_file), exist_ok=True)
    
    with open(output_file, 'w') as f:
        json.dump(results, f, indent=2)
    
    print(f"Results saved to {output_file}")


if __name__ == "__main__":
    run_sensitivity_analysis() 