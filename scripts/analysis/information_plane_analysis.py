#!/usr/bin/env python3
"""
Information Plane Analysis Script

Î² ê°’ ë³€í™”ì— ë”°ë¥¸ Information Plane ë¶„ì„ì„ ìˆ˜í–‰í•©ë‹ˆë‹¤.
IB ì´ë¡ ì˜ í•µì‹¬ì¸ I(Z;X) vs I(Z;Y) íŠ¸ë ˆì´ë“œì˜¤í”„ë¥¼ ì‹œê°í™”í•©ë‹ˆë‹¤.
"""

import numpy as np
import matplotlib.pyplot as plt
import pandas as pd
import os
import json
from typing import Dict, List, Tuple, Any
from scipy import stats
import seaborn as sns

class InformationPlaneAnalyzer:
    def __init__(self, results_dir: str = "outputs/analysis/beta_sensitivity"):
        self.results_dir = results_dir
        self.data = self.load_beta_results()
        
    def load_beta_results(self) -> pd.DataFrame:
        """Î² ë¯¼ê°ë„ ë¶„ì„ ê²°ê³¼ë¥¼ ë¡œë“œí•©ë‹ˆë‹¤."""
        csv_path = os.path.join(self.results_dir, "beta_sensitivity_results.csv")
        if os.path.exists(csv_path):
            return pd.read_csv(csv_path)
        else:
            print(f"âš ï¸ Results file not found: {csv_path}")
            return pd.DataFrame()
    
    def calculate_information_plane_metrics(self) -> pd.DataFrame:
        """Information Plane ë¶„ì„ì„ ìœ„í•œ ë©”íŠ¸ë¦­ì„ ê³„ì‚°í•©ë‹ˆë‹¤."""
        if self.data.empty:
            return pd.DataFrame()
        
        # I(Z;X) = KL Divergence (ì••ì¶•ë¥ /ë³µì¡ë„)
        # I(Z;Y) = Accuracy (ì˜ˆì¸¡ë ¥) - ì •ê·œí™”ëœ ê°’ìœ¼ë¡œ ë³€í™˜
        df = self.data.copy()
        
        # I(Z;X) = KL Divergence (ë¡œê·¸ ìŠ¤ì¼€ì¼ë¡œ ì •ê·œí™”)
        df['I_Z_X'] = np.log1p(df['mean_kl_divergence'])
        
        # I(Z;Y) = Accuracy (0-1 ìŠ¤ì¼€ì¼)
        df['I_Z_Y'] = df['mean_accuracy'] / 100.0
        
        # Î² ê°’ì˜ ë¡œê·¸ ìŠ¤ì¼€ì¼
        df['log_beta'] = np.log10(df['beta'])
        
        return df
    
    def plot_information_plane(self, save_path: str = None) -> Tuple[float, float]:
        """Information Planeì„ ì‹œê°í™”í•©ë‹ˆë‹¤."""
        df = self.calculate_information_plane_metrics()
        if df.empty:
            print("âŒ No data available for Information Plane analysis")
            return None, None
        
        # ê·¸ë˜í”„ ì„¤ì •
        plt.figure(figsize=(12, 10))
        
        # 1. Information Plane (ë©”ì¸ í”Œë¡¯)
        plt.subplot(2, 2, 1)
        
        # Î² ê°’ë³„ë¡œ ìƒ‰ìƒ êµ¬ë¶„
        colors = plt.cm.viridis(np.linspace(0, 1, len(df)))
        
        for i, (_, row) in enumerate(df.iterrows()):
            plt.scatter(row['I_Z_X'], row['I_Z_Y'], 
                       c=[colors[i]], s=150, alpha=0.8,
                       label=f"Î²={row['beta']:.1e}")
        
        # ìµœì  ì  í‘œì‹œ
        best_idx = df['I_Z_Y'].idxmax()
        best_point = df.loc[best_idx]
        plt.scatter(best_point['I_Z_X'], best_point['I_Z_Y'], 
                   c='red', s=200, marker='*', 
                   label=f'Optimal: Î²={best_point["beta"]:.1e}')
        
        plt.xlabel('I(Z;X) = Compression Rate (log KL Divergence)')
        plt.ylabel('I(Z;Y) = Predictive Power (Accuracy)')
        plt.title('Information Plane Analysis')
        plt.grid(True, alpha=0.3)
        plt.legend(bbox_to_anchor=(1.05, 1), loc='upper left')
        
        # 2. Î² vs I(Z;X) ê´€ê³„
        plt.subplot(2, 2, 2)
        plt.scatter(df['log_beta'], df['I_Z_X'], c=colors, s=100, alpha=0.8)
        plt.xlabel('logâ‚â‚€(Î²)')
        plt.ylabel('I(Z;X) = Compression Rate')
        plt.title('Î² vs Compression Rate')
        plt.grid(True, alpha=0.3)
        
        # 3. Î² vs I(Z;Y) ê´€ê³„
        plt.subplot(2, 2, 3)
        plt.scatter(df['log_beta'], df['I_Z_Y'], c=colors, s=100, alpha=0.8)
        plt.xlabel('logâ‚â‚€(Î²)')
        plt.ylabel('I(Z;Y) = Predictive Power')
        plt.title('Î² vs Predictive Power')
        plt.grid(True, alpha=0.3)
        
        # 4. Trade-off ê³¡ì„  (Pareto Frontier)
        plt.subplot(2, 2, 4)
        
        # Pareto optimal points ì°¾ê¸°
        pareto_points = self.find_pareto_frontier(df[['I_Z_X', 'I_Z_Y']].values)
        
        # ëª¨ë“  ì  í”Œë¡¯
        plt.scatter(df['I_Z_X'], df['I_Z_Y'], c='lightblue', s=80, alpha=0.6, label='All Points')
        
        # Pareto frontier í”Œë¡¯
        pareto_x = [df.iloc[i]['I_Z_X'] for i in pareto_points]
        pareto_y = [df.iloc[i]['I_Z_Y'] for i in pareto_points]
        plt.plot(pareto_x, pareto_y, 'r-', linewidth=2, label='Pareto Frontier')
        plt.scatter(pareto_x, pareto_y, c='red', s=100, alpha=0.8)
        
        plt.xlabel('I(Z;X) = Compression Rate')
        plt.ylabel('I(Z;Y) = Predictive Power')
        plt.title('Pareto Frontier (Trade-off Curve)')
        plt.grid(True, alpha=0.3)
        plt.legend()
        
        plt.tight_layout()
        
        if save_path:
            os.makedirs(save_path, exist_ok=True)
            plt.savefig(os.path.join(save_path, 'information_plane_analysis.png'), 
                       dpi=300, bbox_inches='tight')
        
        plt.show()
        
        return best_point['I_Z_X'], best_point['I_Z_Y']
    
    def find_pareto_frontier(self, points: np.ndarray) -> List[int]:
        """Pareto optimal pointsë¥¼ ì°¾ìŠµë‹ˆë‹¤."""
        pareto_points = []
        
        for i, point in enumerate(points):
            is_pareto = True
            for j, other_point in enumerate(points):
                if i != j:
                    # ë‹¤ë¥¸ ì ì´ ì´ ì ì„ ì§€ë°°í•˜ëŠ”ì§€ í™•ì¸
                    if (other_point[0] <= point[0] and other_point[1] >= point[1] and 
                        (other_point[0] < point[0] or other_point[1] > point[1])):
                        is_pareto = False
                        break
            
            if is_pareto:
                pareto_points.append(i)
        
        return pareto_points
    
    def analyze_ib_theory_connection(self) -> Dict[str, Any]:
        """IB ì´ë¡ ê³¼ì˜ ì—°ê²°ì„±ì„ ë¶„ì„í•©ë‹ˆë‹¤."""
        df = self.calculate_information_plane_metrics()
        if df.empty:
            return {}
        
        # 1. ì••ì¶•ë¥ ê³¼ ì˜ˆì¸¡ë ¥ ê°„ì˜ ìƒê´€ê´€ê³„
        correlation = stats.pearsonr(df['I_Z_X'], df['I_Z_Y'])[0]
        
        # 2. ìµœì  Î² ê°’ì—ì„œì˜ íŠ¹ì„±
        best_idx = df['I_Z_Y'].idxmax()
        best_point = df.loc[best_idx]
        
        # 3. Trade-off ë¶„ì„
        # ì••ì¶•ë¥ ì´ ì¦ê°€í•  ë•Œ ì˜ˆì¸¡ë ¥ì´ ì–´ë–»ê²Œ ë³€í•˜ëŠ”ì§€
        compression_gain = df['I_Z_X'].max() - df['I_Z_X'].min()
        prediction_loss = df['I_Z_Y'].max() - df['I_Z_Y'].min()
        
        analysis = {
            'correlation_compression_prediction': correlation,
            'optimal_beta': best_point['beta'],
            'optimal_compression': best_point['I_Z_X'],
            'optimal_prediction': best_point['I_Z_Y'],
            'compression_range': compression_gain,
            'prediction_range': prediction_loss,
            'trade_off_ratio': prediction_loss / compression_gain if compression_gain > 0 else 0
        }
        
        return analysis
    
    def generate_theory_report(self, save_path: str = None) -> str:
        """IB ì´ë¡  ì—°ê²°ì„± ë¶„ì„ ë³´ê³ ì„œë¥¼ ìƒì„±í•©ë‹ˆë‹¤."""
        analysis = self.analyze_ib_theory_connection()
        if not analysis:
            return "No analysis data available"
        
        report = f"""
Information Bottleneck Theory Analysis Report
============================================

1. Compression-Prediction Correlation
   - Pearson correlation: {analysis['correlation_compression_prediction']:.4f}
   - Interpretation: {'Strong negative' if analysis['correlation_compression_prediction'] < -0.7 else 'Moderate negative' if analysis['correlation_compression_prediction'] < -0.3 else 'Weak'} correlation

2. Optimal Operating Point
   - Optimal Î²: {analysis['optimal_beta']:.1e}
   - Compression rate (I(Z;X)): {analysis['optimal_compression']:.4f}
   - Predictive power (I(Z;Y)): {analysis['optimal_prediction']:.4f}

3. Trade-off Analysis
   - Compression range: {analysis['compression_range']:.4f}
   - Prediction range: {analysis['prediction_range']:.4f}
   - Trade-off ratio: {analysis['trade_off_ratio']:.4f}

4. Theoretical Insights
   - The optimal Î² value {analysis['optimal_beta']:.1e} achieves the best balance
     between compression and prediction power
   - This validates the IB theory that there exists an optimal information
     bottleneck strength for knowledge distillation
   - The negative correlation confirms the fundamental trade-off in IB theory
"""
        
        if save_path:
            os.makedirs(save_path, exist_ok=True)
            with open(os.path.join(save_path, 'ib_theory_analysis.txt'), 'w') as f:
                f.write(report)
        
        return report

def run_information_plane_analysis():
    """Information Plane ë¶„ì„ì„ ì‹¤í–‰í•©ë‹ˆë‹¤."""
    print("ğŸ”¬ Starting Information Plane Analysis")
    print("=" * 50)
    
    analyzer = InformationPlaneAnalyzer()
    
    # Information Plane ì‹œê°í™”
    print("ğŸ“Š Generating Information Plane visualization...")
    best_compression, best_prediction = analyzer.plot_information_plane("outputs/analysis/information_plane")
    
    # ì´ë¡  ì—°ê²°ì„± ë¶„ì„
    print("ğŸ“ˆ Analyzing IB theory connection...")
    report = analyzer.generate_theory_report("outputs/analysis/information_plane")
    print(report)
    
    print("âœ… Information Plane analysis completed!")
    print("ğŸ“ Results saved in: outputs/analysis/information_plane/")

if __name__ == "__main__":
    run_information_plane_analysis() 