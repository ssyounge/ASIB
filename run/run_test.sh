#!/usr/bin/env bash
#SBATCH --job-name=run_tests
#SBATCH --partition=base_suma_rtx3090
#SBATCH --gres=gpu:1
#SBATCH --cpus-per-task=4
#SBATCH --mem=32G
#SBATCH --time=2:00:00
#SBATCH --output=/dev/null
#SBATCH --error=/dev/null
# ---------------------------------------------------------
# GPUë¥¼ í™œìš©í•œ ë¹ ë¥¸ í…ŒìŠ¤íŠ¸ ì‹¤í–‰
# tests/ í´ë”ì˜ ëª¨ë“  í…ŒìŠ¤íŠ¸ íŒŒì¼ì„ ë³‘ë ¬ë¡œ ì‹¤í–‰
# ---------------------------------------------------------
set -euo pipefail

# Python í™˜ê²½ ì„¤ì •
echo "ğŸ”§ Setting up Python environment..."
export PATH="$HOME/anaconda3/envs/tlqkf/bin:$PATH"
echo "âœ… Python environment setup completed"
echo ""

# 1) ë¦¬í¬ ìµœìƒìœ„ë¡œ ì´ë™
ROOT="$(git rev-parse --show-toplevel)"
cd "$ROOT"

# 2) PYTHONPATH ì¶”ê°€ ë° í™˜ê²½ ì„¤ì •
export PYTHONPATH="${ROOT}:${PYTHONPATH:-}"
export PATH="$CONDA_PREFIX/bin:$PATH"

# GPU í• ë‹¹ í™•ì¸ ë° ì„¤ì •
echo "ğŸ” Checking GPU allocation..."
if [ -n "$SLURM_GPUS_ON_NODE" ]; then
    # GPU ì¸ë±ìŠ¤ë¥¼ 0ë¶€í„° ì‹œì‘í•˜ë„ë¡ ì¡°ì •
    if [ "$SLURM_GPUS_ON_NODE" = "1" ]; then
        export CUDA_VISIBLE_DEVICES=0
        echo "âœ… CUDA_VISIBLE_DEVICES set to: 0 (mapped from SLURM_GPUS_ON_NODE=1)"
    else
        export CUDA_VISIBLE_DEVICES=0
        echo "âœ… CUDA_VISIBLE_DEVICES set to: 0 (default for any GPU allocation)"
    fi
else
    echo "âš ï¸  SLURM_GPUS_ON_NODE not set, using default GPU 0"
    export CUDA_VISIBLE_DEVICES=0
fi

# CUDA ì»¨í…ìŠ¤íŠ¸ ì´ˆê¸°í™” (segmentation fault ë°©ì§€)
export CUDA_LAUNCH_BLOCKING=1
export PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True

# PyTorch CUDA 12.4 ë¼ì´ë¸ŒëŸ¬ë¦¬ ì‚¬ìš©
export LD_LIBRARY_PATH="$HOME/anaconda3/envs/tlqkf/lib/python3.12/site-packages/torch/lib:$LD_LIBRARY_PATH"
export CUDA_HOME="$HOME/anaconda3/envs/tlqkf/lib/python3.12/site-packages/torch/lib"

# PyTorch CUDA ì„¤ì •
export TORCH_CUDA_ARCH_LIST="8.6"

# CUDA í™˜ê²½ë³€ìˆ˜ (PyTorch ë‚´ì¥ CUDA 12.4 ì‚¬ìš©)
export CUDA_PATH="$HOME/anaconda3/envs/tlqkf/lib/python3.12/site-packages/torch/lib"
export CUDA_ROOT="$HOME/anaconda3/envs/tlqkf/lib/python3.12/site-packages/torch/lib"

# GPU ì •ë³´ ì¶œë ¥
echo "ğŸ” GPU Information:"
nvidia-smi --query-gpu=name,memory.total,memory.free --format=csv,noheader,nounits

# 3) í…ŒìŠ¤íŠ¸ ë””ë ‰í† ë¦¬ ìƒì„±
mkdir -p experiments/test/logs experiments/test/results

# 4) íƒ€ì„ìŠ¤íƒ¬í”„ í•¨ìˆ˜
timestamp() {
    date '+%Y-%m-%d %H:%M:%S'
}

# 5) í…ŒìŠ¤íŠ¸ ê²°ê³¼ íŒŒì‹± í•¨ìˆ˜
parse_test_results() {
    local log_file="$1"
    local test_name="$2"
    
    echo "ğŸ“Š $test_name Results:" | tee -a experiments/test/results/summary.log
    
    # ì„±ê³µ/ì‹¤íŒ¨/ìŠ¤í‚µ/ê²½ê³  ì¹´ìš´íŠ¸ ì¶”ì¶œ
    local passed=$(grep -c "PASSED" "$log_file" 2>/dev/null || echo "0")
    local failed=$(grep -c "FAILED" "$log_file" 2>/dev/null || echo "0")
    local skipped=$(grep -c "SKIPPED" "$log_file" 2>/dev/null || echo "0")
    local warnings=$(grep -c "WARNING" "$log_file" 2>/dev/null || echo "0")
    
    echo "   âœ… PASSED: $passed" | tee -a experiments/test/results/summary.log
    echo "   âŒ FAILED: $failed" | tee -a experiments/test/results/summary.log
    echo "   â­ï¸  SKIPPED: $skipped" | tee -a experiments/test/results/summary.log
    echo "   âš ï¸  WARNINGS: $warnings" | tee -a experiments/test/results/summary.log
    
    # ì‹¤íŒ¨í•œ í…ŒìŠ¤íŠ¸ ëª©ë¡ ì¶”ì¶œ
    if [ "$failed" -gt 0 ]; then
        echo "   ğŸ” Failed tests:" | tee -a experiments/test/results/summary.log
        grep "FAILED" "$log_file" | head -5 | sed 's/^/      /' | tee -a experiments/test/results/summary.log
        if [ "$failed" -gt 5 ]; then
            echo "      ... and $((failed - 5)) more" | tee -a experiments/test/results/summary.log
        fi
    fi
    
    echo "" | tee -a experiments/test/results/summary.log
    
    # ì‹¤íŒ¨ ì—¬ë¶€ ë°˜í™˜
    if [ "$failed" -gt 0 ]; then
        return 1
    else
        return 0
    fi
}

# 6) ë©”ì¸ ì‹¤í–‰ ì‹œì‘
echo "ğŸš€ Starting GPU-accelerated tests at $(timestamp)" | tee experiments/test/results/summary.log
echo "==================================================" | tee -a experiments/test/results/summary.log
echo "Python version: $(python --version)" | tee -a experiments/test/results/summary.log
echo "CUDA available: $(python -c 'import torch; print(torch.cuda.is_available())')" | tee -a experiments/test/results/summary.log
echo "GPU device: $(python -c 'import torch; print(torch.cuda.get_device_name(0) if torch.cuda.is_available() else "CPU")')" | tee -a experiments/test/results/summary.log
echo "==================================================" | tee -a experiments/test/results/summary.log
echo "" | tee -a experiments/test/results/summary.log

# 7) ëª¨ë“  í…ŒìŠ¤íŠ¸ íŒŒì¼ ì°¾ê¸° (conftest.py ì œì™¸)
echo "ğŸ“‹ Discovering test files..." | tee -a experiments/test/results/summary.log
TEST_FILES=($(find tests/ -name "test_*.py" -not -name "conftest.py" | sort))
echo "   Found ${#TEST_FILES[@]} test files" | tee -a experiments/test/results/summary.log
echo "" | tee -a experiments/test/results/summary.log

# 8) í…ŒìŠ¤íŠ¸ ê·¸ë£¹ë³„ë¡œ ë³‘ë ¬ ì‹¤í–‰
echo "ğŸ“‹ Starting test groups at $(timestamp)..." | tee -a experiments/test/results/summary.log

# í•µì‹¬ ASIB í…ŒìŠ¤íŠ¸ (ê°€ì¥ ì¤‘ìš”)
echo "   ğŸ”„ Running core ASIB tests..." | tee -a experiments/test/results/summary.log
python -m pytest tests/test_asib_cl.py tests/test_asib_step.py -v --tb=short -W ignore > experiments/test/logs/core_asib_test.log 2>&1 &
CORE_ASIB_PID=$!

# PyCIL í†µí•© í…ŒìŠ¤íŠ¸
echo "   ğŸ”„ Running PyCIL integration tests..." | tee -a experiments/test/results/summary.log
python -m pytest tests/test_pycil_integration.py tests/test_pycil_models.py -v --tb=short -W ignore > experiments/test/logs/pycil_test.log 2>&1 &
PYCIL_PID=$!

# ë°ì´í„° ë° ìœ í‹¸ë¦¬í‹° í…ŒìŠ¤íŠ¸
echo "   ğŸ”„ Running data and utils tests..." | tee -a experiments/test/results/summary.log
python -m pytest tests/test_data.py tests/test_utils.py tests/test_core.py tests/test_dataset_attributes.py tests/test_dataset_fix.py tests/test_overlap_dataset.py tests/test_main_dataset_loading.py -v --tb=short -W ignore > experiments/test/logs/data_utils_test.log 2>&1 &
DATA_UTILS_PID=$!


# ëª¨ë¸ í…ŒìŠ¤íŠ¸
echo "   ğŸ”„ Running model tests..." | tee -a experiments/test/results/summary.log
python -m pytest tests/test_models.py tests/test_models_advanced.py tests/test_new_methods.py tests/test_new_students.py -v --tb=short -W ignore > experiments/test/logs/models_test.log 2>&1 &
MODELS_PID=$!

# ì„¤ì • ë° ì‹¤í—˜ í…ŒìŠ¤íŠ¸
echo "   ğŸ”„ Running config and experiment tests..." | tee -a experiments/test/results/summary.log
python -m pytest tests/test_configs.py tests/test_finetune_configs.py tests/test_cl_experiments.py tests/test_registry_comprehensive.py tests/test_experiment_configs.py -v --tb=short -W ignore > experiments/test/logs/configs_test.log 2>&1 &
CONFIGS_PID=$!

# ìŠ¤í¬ë¦½íŠ¸ ë° ê¸°íƒ€ í…ŒìŠ¤íŠ¸
echo "   ğŸ”„ Running script and misc tests..." | tee -a experiments/test/results/summary.log
python -m pytest tests/test_scripts.py tests/test_integration.py tests/test_modules.py -v --tb=short -W ignore > experiments/test/logs/scripts_test.log 2>&1 &
SCRIPTS_PID=$!

# KD ë° íŠ¹ìˆ˜ í…ŒìŠ¤íŠ¸
echo "   ğŸ”„ Running KD and special tests..." | tee -a experiments/test/results/summary.log
python -m pytest tests/test_kd_methods.py tests/test_disagreement.py tests/test_ib_mbm_shapes.py tests/test_partial_freeze.py tests/test_mbm_tensor_shapes.py -v --tb=short -W ignore > experiments/test/logs/kd_test.log 2>&1 &
KD_PID=$!

# ìƒˆë¡œìš´ í…ŒìŠ¤íŠ¸ ê·¸ë£¹ë“¤
echo "   ğŸ”„ Running framework robustness tests..." | tee -a experiments/test/results/summary.log
python -m pytest tests/test_framework_robustness.py tests/test_error_prevention.py tests/test_final_validation.py -v --tb=short -W ignore > experiments/test/logs/robustness_test.log 2>&1 &
ROBUSTNESS_PID=$!

echo "   ğŸ”„ Running experiment execution tests..." | tee -a experiments/test/results/summary.log
python -m pytest tests/test_experiment_execution.py tests/test_training_pipeline.py tests/test_main_py_integration.py -v --tb=short -W ignore > experiments/test/logs/execution_test.log 2>&1 &
EXECUTION_PID=$!

echo "   ğŸ”„ Running utility function tests..." | tee -a experiments/test/results/summary.log
python -m pytest tests/test_auto_set_mbm_query_dim.py tests/test_renorm_ce_kd.py tests/test_setup_partial_freeze_schedule.py -v --tb=short -W ignore > experiments/test/logs/utility_test.log 2>&1 &
UTILITY_PID=$!

echo "   ğŸ”„ Running main integration tests..." | tee -a experiments/test/results/summary.log
python -m pytest tests/test_main.py tests/test_main_step_by_step.py tests/test_main_training.py tests/test_training_simple.py -v --tb=short -W ignore > experiments/test/logs/main_integration_test.log 2>&1 &
MAIN_INTEGRATION_PID=$!

echo "   ğŸ”„ Running actual dataset problem tests..." | tee -a experiments/test/results/summary.log
python -m pytest tests/test_actual_dataset_problem.py -v --tb=short -W ignore > experiments/test/logs/dataset_problem_test.log 2>&1 &
DATASET_PROBLEM_PID=$!

# 9) ì‹¤ì‹œê°„ ì§„í–‰ ìƒí™© ëª¨ë‹ˆí„°ë§
echo "" | tee -a experiments/test/results/summary.log
echo "â³ Monitoring test progress..." | tee -a experiments/test/results/summary.log

# ê° í…ŒìŠ¤íŠ¸ ì™„ë£Œ ëŒ€ê¸° ë° ê²°ê³¼ í™•ì¸
wait_and_check() {
    local pid="$1"
    local test_name="$2"
    local log_file="$3"
    
    wait $pid
    echo "   âœ… $test_name completed at $(timestamp)" | tee -a experiments/test/results/summary.log
    parse_test_results "$log_file" "$test_name"
    return $?
}

# ëª¨ë“  í…ŒìŠ¤íŠ¸ ì™„ë£Œ ëŒ€ê¸°
FAILED_COUNT=0

wait_and_check $CORE_ASIB_PID "Core ASIB Tests" "experiments/test/logs/core_asib_test.log" || ((FAILED_COUNT++))
wait_and_check $PYCIL_PID "PyCIL Tests" "experiments/test/logs/pycil_test.log" || ((FAILED_COUNT++))
wait_and_check $DATA_UTILS_PID "Data & Utils Tests" "experiments/test/logs/data_utils_test.log" || ((FAILED_COUNT++))
wait_and_check $MODELS_PID "Model Tests" "experiments/test/logs/models_test.log" || ((FAILED_COUNT++))
wait_and_check $CONFIGS_PID "Config & Experiment Tests" "experiments/test/logs/configs_test.log" || ((FAILED_COUNT++))
wait_and_check $SCRIPTS_PID "Script & Integration Tests" "experiments/test/logs/scripts_test.log" || ((FAILED_COUNT++))
wait_and_check $KD_PID "KD & Special Tests" "experiments/test/logs/kd_test.log" || ((FAILED_COUNT++))
wait_and_check $ROBUSTNESS_PID "Framework Robustness Tests" "experiments/test/logs/robustness_test.log" || ((FAILED_COUNT++))
wait_and_check $EXECUTION_PID "Experiment Execution Tests" "experiments/test/logs/execution_test.log" || ((FAILED_COUNT++))
wait_and_check $UTILITY_PID "Utility Function Tests" "experiments/test/logs/utility_test.log" || ((FAILED_COUNT++))
wait_and_check $MAIN_INTEGRATION_PID "Main Integration Tests" "experiments/test/logs/main_integration_test.log" || ((FAILED_COUNT++))
wait_and_check $DATASET_PROBLEM_PID "Dataset Problem Tests" "experiments/test/logs/dataset_problem_test.log" || ((FAILED_COUNT++))

# 10) ì „ì²´ ê²°ê³¼ ìš”ì•½
echo "==================================================" | tee -a experiments/test/results/summary.log
echo "ğŸ“Š FINAL TEST SUMMARY at $(timestamp)" | tee -a experiments/test/results/summary.log
echo "==================================================" | tee -a experiments/test/results/summary.log

# ì „ì²´ í†µê³„ ê³„ì‚°
TOTAL_PASSED=$(grep "PASSED:" experiments/test/results/summary.log | awk '{sum += $2} END {print sum}')
TOTAL_FAILED=$(grep "FAILED:" experiments/test/results/summary.log | awk '{sum += $2} END {print sum}')
TOTAL_SKIPPED=$(grep "SKIPPED:" experiments/test/results/summary.log | awk '{sum += $2} END {print sum}')
TOTAL_WARNINGS=$(grep "WARNINGS:" experiments/test/results/summary.log | awk '{sum += $2} END {print sum}')

echo "ğŸ¯ Overall Statistics:" | tee -a experiments/test/results/summary.log
echo "   âœ… Total PASSED: $TOTAL_PASSED" | tee -a experiments/test/results/summary.log
echo "   âŒ Total FAILED: $TOTAL_FAILED" | tee -a experiments/test/results/summary.log
echo "   â­ï¸  Total SKIPPED: $TOTAL_SKIPPED" | tee -a experiments/test/results/summary.log
echo "   âš ï¸  Total WARNINGS: $TOTAL_WARNINGS" | tee -a experiments/test/results/summary.log
echo "   ğŸ“ Failed test groups: $FAILED_COUNT" | tee -a experiments/test/results/summary.log
echo "   ğŸ“‹ Total test files: ${#TEST_FILES[@]}" | tee -a experiments/test/results/summary.log

echo "" | tee -a experiments/test/results/summary.log
echo "ğŸ“ Detailed logs available in:" | tee -a experiments/test/results/summary.log
echo "   Summary: experiments/test/results/summary.log" | tee -a experiments/test/results/summary.log
echo "   Individual: experiments/test/logs/*.log" | tee -a experiments/test/results/summary.log

# 11) ìµœì¢… ê²°ê³¼
echo "" | tee -a experiments/test/results/summary.log
echo "==================================================" | tee -a experiments/test/results/summary.log
if [ $FAILED_COUNT -eq 0 ] && [ $TOTAL_FAILED -eq 0 ]; then
    echo "ğŸ‰ ALL TESTS PASSED SUCCESSFULLY!" | tee -a experiments/test/results/summary.log
    echo "âœ… No failures detected" | tee -a experiments/test/results/summary.log
    echo "ğŸ“Š All ${#TEST_FILES[@]} test files processed" | tee -a experiments/test/results/summary.log
    exit 0
else
    echo "âš ï¸  SOME TESTS FAILED" | tee -a experiments/test/results/summary.log
    echo "âŒ $TOTAL_FAILED individual tests failed" | tee -a experiments/test/results/summary.log
    echo "ğŸ“‹ $FAILED_COUNT test groups have failures" | tee -a experiments/test/results/summary.log
    echo "" | tee -a experiments/test/results/summary.log
    echo "ğŸ” To debug specific failures:" | tee -a experiments/test/results/summary.log
    echo "   cat experiments/test/results/summary.log" | tee -a experiments/test/results/summary.log
    echo "   python -m pytest tests/test_<name>.py -v" | tee -a experiments/test/results/summary.log
    exit 1
fi 