#!/usr/bin/env bash
#SBATCH --job-name=asib_ablation_study
#SBATCH --partition=base_suma_rtx3090
#SBATCH --gres=gpu:1
#SBATCH --cpus-per-task=4
#SBATCH --mem=16G
#SBATCH --time=72:00:00
#SBATCH --array=0-4%5            # sbatch ì‹œ --array=0-(N-1)%K ë¡œ ë®ì–´ì¨ì„œ ì‚¬ìš©
#SBATCH --output=experiments/ablation/logs/ablation_%A_%a.log
#SBATCH --error=experiments/ablation/logs/ablation_%A_%a.err

set -euo pipefail
trap 'echo "âŒ Job failed at $(date)"; exit 1' ERR

echo "ğŸ”§ Setting up Python environment..."
# conda non-interactive í™œì„±í™” (set -uë¡œ ì¸í•œ activate hook ì—ëŸ¬ ë°©ì§€)
set +u
if [ -f "$HOME/anaconda3/etc/profile.d/conda.sh" ]; then
  # shellcheck disable=SC1091
  source "$HOME/anaconda3/etc/profile.d/conda.sh"
fi
conda activate tlqkf || {
  export PATH="$HOME/anaconda3/envs/tlqkf/bin:$PATH"
}
set -u
export HYDRA_FULL_ERROR=1
echo "âœ… Python environment setup completed"
echo ""

ROOT="$(git rev-parse --show-toplevel)"
cd "$ROOT"

mkdir -p "$ROOT/experiments/ablation/logs" || true
export PYTHONPATH="${ROOT}:${PYTHONPATH:-}"
export PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True

echo "ğŸ” Checking GPU allocation..."
# export CUDA_VISIBLE_DEVICES=${CUDA_VISIBLE_DEVICES:-0}
echo "âœ… CUDA_VISIBLE_DEVICES set to: ${CUDA_VISIBLE_DEVICES:-<slurm_default>}"

# Array â†’ ìƒ¤ë”© ìë™ ë§¤í•‘
if [[ -n "${SLURM_ARRAY_TASK_ID:-}" ]]; then
  SHARD_IDX="${SLURM_ARRAY_TASK_ID}"
fi
if [[ -n "${SLURM_ARRAY_TASK_COUNT:-}" ]]; then
  SHARD_N="${SLURM_ARRAY_TASK_COUNT}"
elif [[ -n "${SLURM_ARRAY_TASK_MAX:-}" && -n "${SLURM_ARRAY_TASK_MIN:-}" ]]; then
  SHARD_N="$(( SLURM_ARRAY_TASK_MAX - SLURM_ARRAY_TASK_MIN + 1 ))"
fi
SHARD_N="${SHARD_N:-1}"
SHARD_IDX="${SHARD_IDX:-0}"
echo "ğŸ”€ Sharding: SHARD_IDX=${SHARD_IDX} / SHARD_N=${SHARD_N}"
run_idx=0

# CUDA libs guard (ë…¸ë“œë³„ ê²½ë¡œ ì°¨ì´ ëŒ€ì‘)
TORCH_LIB_DIR="$HOME/anaconda3/envs/tlqkf/lib/python3.12/site-packages/torch/lib"
if [ -d "$TORCH_LIB_DIR" ]; then
  unset LD_LIBRARY_PATH || true
  export CUDA_HOME="${CUDA_HOME:-$TORCH_LIB_DIR}"
fi

echo "ğŸ” GPU Information:"
nvidia-smi --query-gpu=name,memory.total,memory.free --format=csv,noheader,nounits || true

# ì‹¤í–‰ ì„¤ì •
# ABLATION_CFG: ë‹¨ì¼ ì‹¤í—˜ í‚¤ ë˜ëŠ” 'ladder'
#   ìœ íš¨ í‚¤: L0_baseline, L1_ib, L2_cccp, L3_asib_cccp, L4_full (ë˜ëŠ” êµ¬í˜• ablation_* ë™ì˜ì–´)
# SEEDS: ê³µë°± êµ¬ë¶„ ë‹¤ì¤‘ seed (ì˜ˆ: "42 87 1337") ì—†ìœ¼ë©´ 42 í•œ ë²ˆ
# EXTRA: ì¶”ê°€ Hydra ì˜¤ë²„ë¼ì´ë“œ (ì˜ˆ: 'experiment.schedule.type=cosine')
CFG_NAME="${ABLATION_CFG:-ladder}"
DRY_RUN="${DRY_RUN:-0}"
SEEDS_STR="${SEEDS:-42}"
EXTRA_OVR="${EXTRA:-}"

CFG_DIR="$ROOT/configs/experiment"

# Ladder ëª¨ë“œ êµ¬ì„± (ì •ê·œí™”ëœ í‚¤)
LADDER_LIST=("L0_baseline" "L1_ib" "L2_cccp" "L3_asib_cccp" "L4_full")

# êµ¬í˜• í‚¤ â†’ ì •ê·œí™”ëœ í‚¤ ë§¤í•‘
map_cfg() {
  case "$1" in
    ablation_baseline) echo "L0_baseline";;
    ablation_ib) echo "L1_ib";;
    ablation_cccp) echo "L2_cccp";;
    ablation_ib_cccp_tadapt) echo "L3_asib_cccp";;
    ablation_full) echo "L4_full";;
    *) echo "$1";;
  esac
}

CANON_NAME="$(map_cfg "$CFG_NAME")"

# ìœ íš¨ì„± ê²€ì‚¬
if [ "$CANON_NAME" != "ladder" ]; then
  CFG_PATH="${CFG_DIR}/${CANON_NAME}.yaml"
  if [ ! -f "$CFG_PATH" ]; then
    echo "âŒ Invalid ABLATION_CFG='${CFG_NAME}' (canon='${CANON_NAME}')."
    echo "   Valid options:"
    echo "   - L0_baseline (ablation_baseline)"
    echo "   - L1_ib (ablation_ib)"
    echo "   - L2_cccp (ablation_cccp)"
    echo "   - L3_asib_cccp (ablation_ib_cccp_tadapt)"
    echo "   - L4_full (ablation_full)"
    echo "   - ladder (runs full ladder set)"
    exit 1
  fi
fi

echo "ğŸ”— Repo: $(git rev-parse --short HEAD) | Branch: $(git rev-parse --abbrev-ref HEAD)"

# DataLoader workers ìë™ ìŠ¤ì¼€ì¼ (ê²½ê³  ë°©ì§€):
# - ê¸°ë³¸ ìƒí•œì€ 4ë¡œ ì œí•œ (í™˜ê²½ë³€ìˆ˜ PYTORCH_WORKERS_MAXë¡œ ì¡°ì • ê°€ëŠ¥)
calc_workers() {
  local cpus="${SLURM_CPUS_PER_TASK:-4}"
  local maxw="${PYTORCH_WORKERS_MAX:-4}"
  # ìµœì†Œ 1 ë³´ì¥, ìƒí•œì€ maxwë¡œ ì œí•œ
  if (( cpus < 1 )); then cpus=1; fi
  if (( cpus > maxw )); then echo "$maxw"; else echo "$cpus"; fi
}

WORKERS="$(calc_workers)"
export OMP_NUM_THREADS="${OMP_NUM_THREADS:-$WORKERS}"
export MKL_NUM_THREADS="${MKL_NUM_THREADS:-$WORKERS}"
echo "ğŸ§µ num_workers(auto)=${WORKERS}, OMP=${OMP_NUM_THREADS}, MKL=${MKL_NUM_THREADS}"

run_one() {
  local cfg="$1"
  local seed="$2"
  local workers_override=""
  # ìë™ ì£¼ì…: EXTRA/CLI ë‘˜ ë‹¤ì— num_workers ì—†ì„ ë•Œë§Œ
  local has_nw=0
  if [[ " ${EXTRA_OVR} " == *"experiment.dataset.num_workers="* || " ${EXTRA_OVR} " == *"dataset.num_workers="* ]]; then
    has_nw=1
  fi
  for arg in "$@"; do
    if [[ "$arg" == experiment.dataset.num_workers=* || "$arg" == dataset.num_workers=* ]]; then
      has_nw=1
    fi
  done
  if [[ $has_nw -eq 0 ]]; then
    # Strict struct: append under experiment.dataset
    workers_override="+experiment.dataset.num_workers=${WORKERS}"
  fi
  echo ""
  echo "ğŸš€ Starting ASIB ablation experiment: ${cfg} | seed=${seed}"
  echo "Time: $(date)"
  # Hydra í˜¸ì¶œ(ê¶Œì¥): -cnìœ¼ë¡œ experiment ê·¸ë£¹ ì„ íƒ, ì˜¤ë²„ë¼ì´ë“œëŠ” ë£¨íŠ¸ í‚¤ë¡œ ì „ë‹¬
  echo "OVERRIDES: ${EXTRA_OVR}"
  # root structì—ëŠ” seedê°€ ì—†ìœ¼ë¯€ë¡œ '+'ë¡œ ì¶”ê°€í•˜ì—¬ Hydra strict ì˜¤ë¥˜ë¥¼ íšŒí”¼
  # Hydra-safe CLIë§Œ íŒ¨ìŠ¤ìŠ¤ë£¨ (key=value, +key=value, ë˜ëŠ” í•˜ì´í”ˆ ì˜µì…˜)
  local passthru_args=()
  for a in "$@"; do
    if [[ "$a" == -* || "$a" == *=* || "$a" == +*=* ]]; then
      passthru_args+=("$a")
    fi
  done
  python -u main.py -cn="experiment/${cfg}" +seed="${seed}" ${EXTRA_OVR} ${workers_override} "${passthru_args[@]}"
  echo "âœ… Finished: ${cfg} | seed=${seed} | Time: $(date)"
}

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ Job Array ë¡œì§ â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# 1) ì‹¤í–‰í•  (cfg,seed) ì¡°í•©ë“¤ì„ RUNS ë°°ì—´ë¡œ êµ¬ì„±
RUNS=()
if [ "$CANON_NAME" = "ladder" ]; then
  echo "ğŸ“š Ladder sequence: ${LADDER_LIST[*]}"
  for s in ${SEEDS_STR}; do
    for cfg in "${LADDER_LIST[@]}"; do
      if [ -f "${CFG_DIR}/${cfg}.yaml" ]; then
        RUNS+=("${cfg}|${s}")
      else
        echo "âš ï¸  Skipping missing config: ${cfg}"
      fi
    done
  done
else
  if [ -f "${CFG_DIR}/${CANON_NAME}.yaml" ]; then
    for s in ${SEEDS_STR}; do
      RUNS+=("${CANON_NAME}|${s}")
    done
  else
    echo "âŒ Invalid ABLATION_CFG='${CFG_NAME}' (canon='${CANON_NAME}')."
    exit 1
  fi
fi

N_RUNS=${#RUNS[@]}
echo "ğŸ§® Planned runs: ${N_RUNS}"

# ë°°ì—´ í¬ê¸°ì— ë§ê²Œ RUNS ìë™ í™•ì¥ (seed ì¦ê°€ë¡œ ìœ ë‹ˆí¬ ë³´ì¥)
if [[ -n "${SLURM_ARRAY_TASK_COUNT:-}" ]]; then
  TARGET=${SLURM_ARRAY_TASK_COUNT}
  if (( N_RUNS < TARGET && N_RUNS > 0 )); then
    NEW_RUNS=()
    for (( i=0; i<TARGET; i++ )); do
      base_idx=$(( i % N_RUNS ))
      IFS='|' read -r CFG_I SEED_I <<< "${RUNS[$base_idx]}"
      NEW_SEED=$(( SEED_I + i ))
      NEW_RUNS+=("${CFG_I}|${NEW_SEED}")
    done
    RUNS=("${NEW_RUNS[@]}")
    N_RUNS=${#RUNS[@]}
    echo "ğŸ§© Auto-expanded RUNS to match array: ${N_RUNS}"
  fi
fi

if (( DRY_RUN > 0 )); then
  echo "ğŸ“‹ This shard will run:"
  for i in $(seq 0 $((N_RUNS-1))); do
    if (( SHARD_N > 1 )); then
      if (( (i % SHARD_N) != SHARD_IDX )); then continue; fi
    fi
    echo "  - [$i] ${RUNS[$i]}"
  done
  echo "ğŸ” Tip: sbatch --array=0-$((SHARD_N-1))%$SHARD_N run/run_asib_ablation_study.sh ABLATION_CFG=${CFG_NAME} SEEDS=\"${SEEDS_STR}\""
  exit 0
fi

# 2) Array index â†’ run index ë§¤í•‘ (ê° íƒœìŠ¤í¬ê°€ ì •í™•íˆ 1ê°œ ëŸ° ìˆ˜í–‰)
if [[ -n "${SLURM_ARRAY_TASK_ID:-}" ]]; then
  idx="${SLURM_ARRAY_TASK_ID}"
  if (( idx >= N_RUNS )); then
    echo "â„¹ï¸  Array index ${idx} >= N_RUNS ${N_RUNS} â†’ nothing to do."; exit 0
  fi
  IFS='|' read -r CFG_I SEED_I <<< "${RUNS[$idx]}"
  run_one "${CFG_I}" "${SEED_I}"
else
  for rs in "${RUNS[@]}"; do
    IFS='|' read -r CFG_I SEED_I <<< "$rs"
    run_one "${CFG_I}" "${SEED_I}"
  done
fi

echo ""
echo "âœ… All runs completed at $(date)"