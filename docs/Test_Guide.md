# PyCIL & ASIB-CL í…ŒìŠ¤íŠ¸ ê°€ì´ë“œ

## ğŸ“– ê°œìš”

ì´ ë¬¸ì„œëŠ” PyCIL í”„ë ˆì„ì›Œí¬ í†µí•©ê³¼ ASIB-CL ëª¨ë¸ êµ¬í˜„ì— ëŒ€í•œ í¬ê´„ì ì¸ í…ŒìŠ¤íŠ¸ ê°€ì´ë“œì…ë‹ˆë‹¤. ë‹¨ìœ„ í…ŒìŠ¤íŠ¸ë¶€í„° í†µí•© í…ŒìŠ¤íŠ¸ê¹Œì§€ ëª¨ë“  í…ŒìŠ¤íŠ¸ ì‹œë‚˜ë¦¬ì˜¤ë¥¼ ë‹¤ë£¹ë‹ˆë‹¤.

## ğŸ¯ í…ŒìŠ¤íŠ¸ ëª©í‘œ

- **PyCIL í†µí•© ê²€ì¦**: í”„ë ˆì„ì›Œí¬ê°€ ì˜¬ë°”ë¥´ê²Œ í†µí•©ë˜ì—ˆëŠ”ì§€ í™•ì¸
- **ASIB-CL ëª¨ë¸ ê²€ì¦**: ëª¨ë¸ì´ ì •ìƒì ìœ¼ë¡œ ì‘ë™í•˜ëŠ”ì§€ í™•ì¸
- **ì‹¤í—˜ í™˜ê²½ ê²€ì¦**: ì „ì²´ ì‹¤í—˜ íŒŒì´í”„ë¼ì¸ì´ ì •ìƒ ì‘ë™í•˜ëŠ”ì§€ í™•ì¸
- **ì„±ëŠ¥ ê²€ì¦**: ì˜ˆìƒëœ ì„±ëŠ¥ì´ ë‚˜ì˜¤ëŠ”ì§€ í™•ì¸

## ğŸ“ í…ŒìŠ¤íŠ¸ íŒŒì¼ êµ¬ì¡°

```
tests/
â”œâ”€â”€ test_pycil_integration.py      # PyCIL í†µí•© í…ŒìŠ¤íŠ¸
â”œâ”€â”€ test_asib_cl.py                # ASIB-CL ëª¨ë¸ í…ŒìŠ¤íŠ¸
â”œâ”€â”€ test_cl_experiments.py         # CL ì‹¤í—˜ í…ŒìŠ¤íŠ¸
â”œâ”€â”€ test_data_loading.py           # ë°ì´í„° ë¡œë”© í…ŒìŠ¤íŠ¸
â”œâ”€â”€ test_config_validation.py      # ì„¤ì • íŒŒì¼ ê²€ì¦ í…ŒìŠ¤íŠ¸
â””â”€â”€ conftest.py                    # pytest ì„¤ì • ë° ê³µí†µ fixture
```

## ğŸ§ª í…ŒìŠ¤íŠ¸ ì‹¤í–‰ ë°©ë²•

### 1. ì „ì²´ í…ŒìŠ¤íŠ¸ ì‹¤í–‰
```bash
# ëª¨ë“  í…ŒìŠ¤íŠ¸ ì‹¤í–‰
pytest tests/ -v

# íŠ¹ì • í…ŒìŠ¤íŠ¸ íŒŒì¼ ì‹¤í–‰
pytest tests/test_asib_cl.py -v

# íŠ¹ì • í…ŒìŠ¤íŠ¸ í•¨ìˆ˜ ì‹¤í–‰
pytest tests/test_asib_cl.py::test_asib_cl_initialization -v
```

### 2. ì»¤ë²„ë¦¬ì§€ì™€ í•¨ê»˜ ì‹¤í–‰
```bash
pytest tests/ --cov=PyCIL --cov-report=html
```

### 3. ë³‘ë ¬ ì‹¤í–‰
```bash
pytest tests/ -n auto
```

## ğŸ”§ í…ŒìŠ¤íŠ¸ í™˜ê²½ ì„¤ì •

### 1. pytest ì„¤ì • (conftest.py)
```python
import pytest
import torch
import numpy as np
import sys
import os

# PyCIL ê²½ë¡œ ì¶”ê°€
sys.path.append('./PyCIL')

@pytest.fixture(scope="session")
def device():
    """í…ŒìŠ¤íŠ¸ìš© ë””ë°”ì´ìŠ¤ ì„¤ì •"""
    if torch.cuda.is_available():
        return torch.device("cuda:0")
    else:
        return torch.device("cpu")

@pytest.fixture(scope="session")
def sample_args():
    """í…ŒìŠ¤íŠ¸ìš© ê¸°ë³¸ ì„¤ì •"""
    return {
        "prefix": "test",
        "dataset": "cifar100",
        "memory_size": 100,
        "memory_per_class": 10,
        "fixed_memory": False,
        "shuffle": True,
        "init_cls": 5,
        "increment": 5,
        "model_name": "asib_cl",
        "convnet_type": "resnet32",
        "device": ["0"],
        "seed": [1993],
        "ib_beta": 0.1
    }

@pytest.fixture(scope="session")
def small_dataset():
    """ì‘ì€ í…ŒìŠ¤íŠ¸ ë°ì´í„°ì…‹"""
    # ì‹¤ì œ ë°ì´í„° ëŒ€ì‹  ë”ë¯¸ ë°ì´í„° ì‚¬ìš©
    return torch.randn(100, 3, 32, 32), torch.randint(0, 10, (100,))
```

## ğŸ“‹ í…ŒìŠ¤íŠ¸ ì¼€ì´ìŠ¤ ìƒì„¸

### 1. PyCIL í†µí•© í…ŒìŠ¤íŠ¸ (test_pycil_integration.py)

#### ê¸°ë³¸ í†µí•© ê²€ì¦
```python
def test_pycil_import():
    """PyCIL ëª¨ë“ˆë“¤ì´ ì •ìƒì ìœ¼ë¡œ importë˜ëŠ”ì§€ í™•ì¸"""
    try:
        from PyCIL.models.base import BaseLearner
        from PyCIL.utils.factory import get_model
        from PyCIL.utils.data_manager import DataManager
        assert True
    except ImportError as e:
        pytest.fail(f"PyCIL import ì‹¤íŒ¨: {e}")

def test_factory_registration():
    """ASIB-CLì´ factoryì— ì •ìƒì ìœ¼ë¡œ ë“±ë¡ë˜ì—ˆëŠ”ì§€ í™•ì¸"""
    from PyCIL.utils.factory import get_model
    from PyCIL.models.asib_cl import ASIB_CL
    
    args = sample_args()
    model = get_model("asib_cl", args)
    assert isinstance(model, ASIB_CL)
```

#### ì„¤ì • íŒŒì¼ ê²€ì¦
```python
def test_config_file_exists():
    """ASIB-CL ì„¤ì • íŒŒì¼ì´ ì¡´ì¬í•˜ëŠ”ì§€ í™•ì¸"""
    config_path = "PyCIL/exps/asib_cl.json"
    assert os.path.exists(config_path), f"ì„¤ì • íŒŒì¼ì´ ì—†ìŠµë‹ˆë‹¤: {config_path}"

def test_config_file_valid():
    """ì„¤ì • íŒŒì¼ì´ ìœ íš¨í•œ JSONì¸ì§€ í™•ì¸"""
    import json
    config_path = "PyCIL/exps/asib_cl.json"
    
    with open(config_path, 'r') as f:
        config = json.load(f)
    
    required_keys = ["model_name", "convnet_type", "dataset", "ib_beta"]
    for key in required_keys:
        assert key in config, f"í•„ìˆ˜ í‚¤ê°€ ì—†ìŠµë‹ˆë‹¤: {key}"
    
    assert config["model_name"] == "asib_cl"
    assert config["ib_beta"] == 0.1
```

### 2. ASIB-CL ëª¨ë¸ í…ŒìŠ¤íŠ¸ (test_asib_cl.py)

#### ëª¨ë¸ ì´ˆê¸°í™” í…ŒìŠ¤íŠ¸
```python
def test_asib_cl_initialization(sample_args):
    """ASIB-CL ëª¨ë¸ì´ ì •ìƒì ìœ¼ë¡œ ì´ˆê¸°í™”ë˜ëŠ”ì§€ í™•ì¸"""
    from PyCIL.models.asib_cl import ASIB_CL
    
    model = ASIB_CL(sample_args)
    
    # ê¸°ë³¸ ì†ì„± í™•ì¸
    assert hasattr(model, '_network')
    assert hasattr(model, '_old_network')
    assert hasattr(model, '_ib_beta')
    assert hasattr(model, '_ib_encoder')
    assert hasattr(model, '_ib_decoder')
    
    # ì´ˆê¸°ê°’ í™•ì¸
    assert model._ib_beta == 0.1
    assert model._old_network is None
    assert model._ib_encoder is None
    assert model._ib_decoder is None

def test_ib_modules_initialization(sample_args):
    """IB ëª¨ë“ˆì´ ì •ìƒì ìœ¼ë¡œ ì´ˆê¸°í™”ë˜ëŠ”ì§€ í™•ì¸"""
    from PyCIL.models.asib_cl import ASIB_CL
    
    model = ASIB_CL(sample_args)
    
    # ë”ë¯¸ ë„¤íŠ¸ì›Œí¬ ìƒì„±
    class DummyNetwork:
        def __init__(self):
            self.feature_dim = 512
    
    model._old_network = DummyNetwork()
    model._init_ib_modules(512)
    
    # IB ëª¨ë“ˆ êµ¬ì¡° í™•ì¸
    assert model._ib_encoder is not None
    assert model._ib_decoder is not None
    
    # ì…ë ¥ ì°¨ì› í™•ì¸
    dummy_input = torch.randn(10, 512)
    encoder_output = model._ib_encoder(dummy_input)
    assert encoder_output.shape == (10, 256)  # latent_dim * 2
    
    # ë””ì½”ë” í…ŒìŠ¤íŠ¸
    latent_dim = 512 // 4  # 128
    dummy_latent = torch.randn(10, latent_dim)
    decoder_output = model._ib_decoder(dummy_latent)
    assert decoder_output.shape == (10, 512)
```

#### IB ì†ì‹¤ í•¨ìˆ˜ í…ŒìŠ¤íŠ¸
```python
def test_ib_distillation_loss(sample_args):
    """IB ê¸°ë°˜ ì§€ì‹ ì¦ë¥˜ ì†ì‹¤ì´ ì •ìƒì ìœ¼ë¡œ ê³„ì‚°ë˜ëŠ”ì§€ í™•ì¸"""
    from PyCIL.models.asib_cl import ASIB_CL
    
    model = ASIB_CL(sample_args)
    
    # ë”ë¯¸ ë°ì´í„° ìƒì„±
    batch_size = 16
    feature_dim = 512
    student_features = torch.randn(batch_size, feature_dim)
    teacher_features = torch.randn(batch_size, feature_dim)
    
    # IB ëª¨ë“ˆ ì´ˆê¸°í™”
    model._old_network = type('DummyNetwork', (), {'feature_dim': feature_dim})()
    model._init_ib_modules(feature_dim)
    
    # ì†ì‹¤ ê³„ì‚°
    loss = model._ib_distillation_loss(student_features, teacher_features)
    
    # ì†ì‹¤ì´ ìŠ¤ì¹¼ë¼ì´ê³  ì–‘ìˆ˜ì¸ì§€ í™•ì¸
    assert isinstance(loss, torch.Tensor)
    assert loss.dim() == 0  # ìŠ¤ì¹¼ë¼
    assert loss.item() > 0  # ì–‘ìˆ˜

def test_reparameterization_trick(sample_args):
    """Reparameterization trickì´ ì •ìƒì ìœ¼ë¡œ ì‘ë™í•˜ëŠ”ì§€ í™•ì¸"""
    from PyCIL.models.asib_cl import ASIB_CL
    
    model = ASIB_CL(sample_args)
    
    # ë”ë¯¸ mu, logvar ìƒì„±
    batch_size = 16
    latent_dim = 128
    mu = torch.randn(batch_size, latent_dim)
    logvar = torch.randn(batch_size, latent_dim)
    
    # Reparameterization
    z = model._reparameterize(mu, logvar)
    
    # ì¶œë ¥ í˜•íƒœ í™•ì¸
    assert z.shape == (batch_size, latent_dim)
    assert isinstance(z, torch.Tensor)
```

#### ë©”ëª¨ë¦¬ ê´€ë¦¬ í…ŒìŠ¤íŠ¸
```python
def test_memory_management(sample_args):
    """ë©”ëª¨ë¦¬ ê´€ë¦¬ ê¸°ëŠ¥ì´ ì •ìƒì ìœ¼ë¡œ ì‘ë™í•˜ëŠ”ì§€ í™•ì¸"""
    from PyCIL.models.asib_cl import ASIB_CL
    
    model = ASIB_CL(sample_args)
    
    # ì´ˆê¸° ë©”ëª¨ë¦¬ ìƒíƒœ í™•ì¸
    assert len(model._data_memory) == 0
    assert len(model._targets_memory) == 0
    
    # ë”ë¯¸ ë©”ëª¨ë¦¬ ë°ì´í„° ì¶”ê°€
    dummy_data = np.random.randn(50, 3, 32, 32)
    dummy_targets = np.random.randint(0, 10, 50)
    
    model._data_memory = dummy_data
    model._targets_memory = dummy_targets
    
    # ë©”ëª¨ë¦¬ ë°˜í™˜ í…ŒìŠ¤íŠ¸
    memory = model._get_memory()
    assert memory is not None
    assert len(memory) == 2
    assert memory[0].shape == dummy_data.shape
    assert memory[1].shape == dummy_targets.shape
```

### 3. CL ì‹¤í—˜ í…ŒìŠ¤íŠ¸ (test_cl_experiments.py)

#### ì‹¤í—˜ ì„¤ì • ê²€ì¦
```python
def test_experiment_configs():
    """ëª¨ë“  ì‹¤í—˜ ì„¤ì • íŒŒì¼ì´ ìœ íš¨í•œì§€ í™•ì¸"""
    import json
    import glob
    
    config_files = glob.glob("PyCIL/exps/*.json")
    
    for config_file in config_files:
        with open(config_file, 'r') as f:
            try:
                config = json.load(f)
                # ê¸°ë³¸ í•„ìˆ˜ í‚¤ í™•ì¸
                required_keys = ["model_name", "convnet_type", "dataset"]
                for key in required_keys:
                    assert key in config, f"{config_file}: {key} í‚¤ê°€ ì—†ìŠµë‹ˆë‹¤"
            except json.JSONDecodeError as e:
                pytest.fail(f"{config_file}: JSON íŒŒì‹± ì‹¤íŒ¨ - {e}")

def test_asib_cl_config_specific():
    """ASIB-CL ì„¤ì •ì˜ íŠ¹ì • ê°’ë“¤ì´ ì˜¬ë°”ë¥¸ì§€ í™•ì¸"""
    import json
    
    with open("PyCIL/exps/asib_cl.json", 'r') as f:
        config = json.load(f)
    
    # ASIB-CL íŠ¹í™” ì„¤ì • í™•ì¸
    assert config["model_name"] == "asib_cl"
    assert "ib_beta" in config
    assert isinstance(config["ib_beta"], (int, float))
    assert 0 < config["ib_beta"] < 1
```

#### ë°ì´í„° ë¡œë”© í…ŒìŠ¤íŠ¸
```python
def test_data_manager_initialization(sample_args):
    """DataManagerê°€ ì •ìƒì ìœ¼ë¡œ ì´ˆê¸°í™”ë˜ëŠ”ì§€ í™•ì¸"""
    from PyCIL.utils.data_manager import DataManager
    
    data_manager = DataManager(
        dataset=sample_args["dataset"],
        shuffle=sample_args["shuffle"],
        seed=sample_args["seed"][0],
        init_cls=sample_args["init_cls"],
        increment=sample_args["increment"]
    )
    
    assert data_manager.nb_tasks > 0
    assert data_manager.total_classes == 100  # CIFAR-100

def test_dataset_loading(sample_args):
    """ë°ì´í„°ì…‹ì´ ì •ìƒì ìœ¼ë¡œ ë¡œë“œë˜ëŠ”ì§€ í™•ì¸"""
    from PyCIL.utils.data_manager import DataManager
    
    data_manager = DataManager(
        dataset=sample_args["dataset"],
        shuffle=sample_args["shuffle"],
        seed=sample_args["seed"][0],
        init_cls=sample_args["init_cls"],
        increment=sample_args["increment"]
    )
    
    # ì²« ë²ˆì§¸ íƒœìŠ¤í¬ ë°ì´í„° ë¡œë“œ
    train_dataset = data_manager.get_dataset(
        np.arange(0, sample_args["init_cls"]),
        source="train",
        mode="train"
    )
    
    assert len(train_dataset) > 0
    
    # ë°ì´í„° ìƒ˜í”Œ í™•ì¸
    sample_data, sample_target = train_dataset[0]
    assert sample_data.shape == (3, 32, 32)  # CIFAR-100 ì´ë¯¸ì§€ í¬ê¸°
    assert 0 <= sample_target < sample_args["init_cls"]
```

### 4. ì„±ëŠ¥ í…ŒìŠ¤íŠ¸ (test_performance.py)

#### ë©”ëª¨ë¦¬ ì‚¬ìš©ëŸ‰ í…ŒìŠ¤íŠ¸
```python
def test_memory_usage(sample_args):
    """ëª¨ë¸ì˜ ë©”ëª¨ë¦¬ ì‚¬ìš©ëŸ‰ì´ í•©ë¦¬ì ì¸ì§€ í™•ì¸"""
    import psutil
    import torch
    
    from PyCIL.models.asib_cl import ASIB_CL
    
    # ë©”ëª¨ë¦¬ ì‚¬ìš©ëŸ‰ ì¸¡ì • ì‹œì‘
    process = psutil.Process()
    initial_memory = process.memory_info().rss / 1024 / 1024  # MB
    
    # ëª¨ë¸ ìƒì„±
    model = ASIB_CL(sample_args)
    
    # ë”ë¯¸ ë°ì´í„°ë¡œ forward pass
    dummy_input = torch.randn(32, 3, 32, 32)
    if torch.cuda.is_available():
        dummy_input = dummy_input.cuda()
        model._network = model._network.cuda()
    
    with torch.no_grad():
        _ = model._network(dummy_input)
    
    # ë©”ëª¨ë¦¬ ì‚¬ìš©ëŸ‰ ì¸¡ì •
    final_memory = process.memory_info().rss / 1024 / 1024  # MB
    memory_increase = final_memory - initial_memory
    
    # ë©”ëª¨ë¦¬ ì¦ê°€ëŸ‰ì´ í•©ë¦¬ì ì¸ì§€ í™•ì¸ (ì˜ˆ: 2GB ì´í•˜)
    assert memory_increase < 2048, f"ë©”ëª¨ë¦¬ ì‚¬ìš©ëŸ‰ì´ ë„ˆë¬´ í½ë‹ˆë‹¤: {memory_increase:.2f}MB"
```

#### í•™ìŠµ ì†ë„ í…ŒìŠ¤íŠ¸
```python
def test_training_speed(sample_args):
    """í•™ìŠµ ì†ë„ê°€ í•©ë¦¬ì ì¸ì§€ í™•ì¸"""
    import time
    from PyCIL.models.asib_cl import ASIB_CL
    
    model = ASIB_CL(sample_args)
    
    # ë”ë¯¸ ë°ì´í„° ìƒì„±
    batch_size = 32
    dummy_input = torch.randn(batch_size, 3, 32, 32)
    dummy_target = torch.randint(0, 10, (batch_size,))
    
    if torch.cuda.is_available():
        dummy_input = dummy_input.cuda()
        dummy_target = dummy_target.cuda()
        model._network = model._network.cuda()
    
    # í•™ìŠµ ì‹œê°„ ì¸¡ì •
    start_time = time.time()
    
    model._network.train()
    optimizer = torch.optim.SGD(model._network.parameters(), lr=0.01)
    
    for _ in range(10):  # 10ë²ˆì˜ forward/backward pass
        optimizer.zero_grad()
        outputs = model._network(dummy_input)
        if isinstance(outputs, dict):
            outputs = outputs['logits']
        loss = torch.nn.functional.cross_entropy(outputs, dummy_target)
        loss.backward()
        optimizer.step()
    
    end_time = time.time()
    training_time = end_time - start_time
    
    # í•™ìŠµ ì‹œê°„ì´ í•©ë¦¬ì ì¸ì§€ í™•ì¸ (ì˜ˆ: 10ì´ˆ ì´í•˜)
    assert training_time < 10, f"í•™ìŠµ ì‹œê°„ì´ ë„ˆë¬´ ê¹ë‹ˆë‹¤: {training_time:.2f}ì´ˆ"
```

## ğŸ” ë””ë²„ê¹… í…ŒìŠ¤íŠ¸

### 1. ì˜¤ë¥˜ ìƒí™© í…ŒìŠ¤íŠ¸
```python
def test_error_handling():
    """ì˜¤ë¥˜ ìƒí™©ì—ì„œ ì ì ˆíˆ ì²˜ë¦¬ë˜ëŠ”ì§€ í™•ì¸"""
    from PyCIL.models.asib_cl import ASIB_CL
    
    # ì˜ëª»ëœ ì„¤ì •ìœ¼ë¡œ ëª¨ë¸ ìƒì„± ì‹œë„
    invalid_args = {"invalid_key": "invalid_value"}
    
    with pytest.raises(Exception):
        model = ASIB_CL(invalid_args)

def test_edge_cases():
    """ì—£ì§€ ì¼€ì´ìŠ¤ì—ì„œ ì •ìƒì ìœ¼ë¡œ ì‘ë™í•˜ëŠ”ì§€ í™•ì¸"""
    from PyCIL.models.asib_cl import ASIB_CL
    
    # ë¹ˆ ë°°ì¹˜ í…ŒìŠ¤íŠ¸
    sample_args = {
        "prefix": "test",
        "dataset": "cifar100",
        "memory_size": 0,  # ë¹ˆ ë©”ëª¨ë¦¬
        "memory_per_class": 0,
        "fixed_memory": False,
        "shuffle": True,
        "init_cls": 1,  # ìµœì†Œ í´ë˜ìŠ¤ ìˆ˜
        "increment": 1,
        "model_name": "asib_cl",
        "convnet_type": "resnet32",
        "device": ["0"],
        "seed": [1993],
        "ib_beta": 0.1
    }
    
    model = ASIB_CL(sample_args)
    assert model is not None
```

### 2. ë¡œê¹… í…ŒìŠ¤íŠ¸
```python
def test_logging_functionality():
    """ë¡œê¹… ê¸°ëŠ¥ì´ ì •ìƒì ìœ¼ë¡œ ì‘ë™í•˜ëŠ”ì§€ í™•ì¸"""
    import logging
    from PyCIL.models.asib_cl import ASIB_CL
    
    # ë¡œê¹… ì„¤ì •
    logging.basicConfig(level=logging.INFO)
    logger = logging.getLogger(__name__)
    
    # ë¡œê·¸ ë©”ì‹œì§€ ìº¡ì²˜
    log_messages = []
    
    class TestHandler(logging.Handler):
        def emit(self, record):
            log_messages.append(record.getMessage())
    
    logger.addHandler(TestHandler())
    
    # ëª¨ë¸ ì´ˆê¸°í™” (ë¡œê¹… ë°œìƒ)
    sample_args = {
        "prefix": "test",
        "dataset": "cifar100",
        "memory_size": 100,
        "memory_per_class": 10,
        "fixed_memory": False,
        "shuffle": True,
        "init_cls": 5,
        "increment": 5,
        "model_name": "asib_cl",
        "convnet_type": "resnet32",
        "device": ["0"],
        "seed": [1993],
        "ib_beta": 0.1
    }
    
    model = ASIB_CL(sample_args)
    
    # ë¡œê·¸ ë©”ì‹œì§€ê°€ ìƒì„±ë˜ì—ˆëŠ”ì§€ í™•ì¸
    assert len(log_messages) > 0
```

## ğŸ“Š í…ŒìŠ¤íŠ¸ ê²°ê³¼ ë¶„ì„

### 1. í…ŒìŠ¤íŠ¸ ì»¤ë²„ë¦¬ì§€
```bash
# ì»¤ë²„ë¦¬ì§€ ë¦¬í¬íŠ¸ ìƒì„±
pytest tests/ --cov=PyCIL --cov-report=html --cov-report=term-missing
```

### 2. ì„±ëŠ¥ ë²¤ì¹˜ë§ˆí¬
```python
def benchmark_performance():
    """ì„±ëŠ¥ ë²¤ì¹˜ë§ˆí¬ ì‹¤í–‰"""
    import time
    import torch
    
    # ë‹¤ì–‘í•œ ë°°ì¹˜ í¬ê¸°ë¡œ í…ŒìŠ¤íŠ¸
    batch_sizes = [16, 32, 64, 128]
    results = {}
    
    for batch_size in batch_sizes:
        start_time = time.time()
        
        # ëª¨ë¸ ìƒì„± ë° forward pass
        dummy_input = torch.randn(batch_size, 3, 32, 32)
        # ... í…ŒìŠ¤íŠ¸ ì½”ë“œ ...
        
        end_time = time.time()
        results[batch_size] = end_time - start_time
    
    return results
```

## ğŸš€ CI/CD í†µí•©

### 1. GitHub Actions ì„¤ì •
```yaml
# .github/workflows/test.yml
name: PyCIL & ASIB-CL Tests

on: [push, pull_request]

jobs:
  test:
    runs-on: ubuntu-latest
    
    steps:
    - uses: actions/checkout@v2
    
    - name: Set up Python
      uses: actions/setup-python@v2
      with:
        python-version: 3.9
    
    - name: Install dependencies
      run: |
        pip install torch torchvision
        pip install pytest pytest-cov
        pip install scipy quadprog POT
    
    - name: Run tests
      run: |
        pytest tests/ -v --cov=PyCIL --cov-report=xml
    
    - name: Upload coverage
      uses: codecov/codecov-action@v1
```

### 2. í…ŒìŠ¤íŠ¸ ìë™í™” ìŠ¤í¬ë¦½íŠ¸
```bash
#!/bin/bash
# run_tests.sh

echo "ğŸ§ª PyCIL & ASIB-CL í…ŒìŠ¤íŠ¸ ì‹œì‘"

# 1. ê¸°ë³¸ í…ŒìŠ¤íŠ¸
echo "ğŸ“‹ ê¸°ë³¸ í…ŒìŠ¤íŠ¸ ì‹¤í–‰..."
pytest tests/ -v

# 2. ì»¤ë²„ë¦¬ì§€ í…ŒìŠ¤íŠ¸
echo "ğŸ“Š ì»¤ë²„ë¦¬ì§€ í…ŒìŠ¤íŠ¸ ì‹¤í–‰..."
pytest tests/ --cov=PyCIL --cov-report=html

# 3. ì„±ëŠ¥ í…ŒìŠ¤íŠ¸
echo "âš¡ ì„±ëŠ¥ í…ŒìŠ¤íŠ¸ ì‹¤í–‰..."
python -m pytest tests/test_performance.py -v

# 4. ê²°ê³¼ ìš”ì•½
echo "ğŸ“ˆ í…ŒìŠ¤íŠ¸ ê²°ê³¼ ìš”ì•½..."
echo "ì»¤ë²„ë¦¬ì§€ ë¦¬í¬íŠ¸: htmlcov/index.html"
echo "í…ŒìŠ¤íŠ¸ ì™„ë£Œ!"
```

## ğŸ” ë¬¸ì œ í•´ê²°

### 1. ì¼ë°˜ì ì¸ í…ŒìŠ¤íŠ¸ ì‹¤íŒ¨

#### Import ì˜¤ë¥˜
```bash
# PyCIL ê²½ë¡œ ë¬¸ì œ
export PYTHONPATH="${PYTHONPATH}:./PyCIL"
```

#### CUDA ë©”ëª¨ë¦¬ ë¶€ì¡±
```python
# CPUì—ì„œ í…ŒìŠ¤íŠ¸ ì‹¤í–‰
@pytest.fixture(scope="session")
def device():
    return torch.device("cpu")
```

#### ë°ì´í„°ì…‹ ë‹¤ìš´ë¡œë“œ ì‹¤íŒ¨
```python
# ë”ë¯¸ ë°ì´í„° ì‚¬ìš©
@pytest.fixture(scope="session")
def mock_dataset():
    return torch.randn(100, 3, 32, 32), torch.randint(0, 10, (100,))
```

### 2. ë””ë²„ê¹… íŒ

#### ìƒì„¸í•œ ë¡œê·¸ ì¶œë ¥
```bash
pytest tests/ -v -s --tb=long
```

#### íŠ¹ì • í…ŒìŠ¤íŠ¸ë§Œ ì‹¤í–‰
```bash
pytest tests/test_asib_cl.py::test_ib_distillation_loss -v -s
```

#### ë©”ëª¨ë¦¬ í”„ë¡œíŒŒì¼ë§
```bash
pip install memory-profiler
python -m memory_profiler tests/test_performance.py
```

## ğŸ“š ì°¸ê³  ìë£Œ

1. **pytest ê³µì‹ ë¬¸ì„œ**: https://docs.pytest.org/
2. **PyTorch í…ŒìŠ¤íŠ¸ ê°€ì´ë“œ**: https://pytorch.org/docs/stable/testing.html
3. **Python í…ŒìŠ¤íŠ¸ ëª¨ë²” ì‚¬ë¡€**: https://realpython.com/python-testing/

## ğŸ¤ ê¸°ì—¬ ê°€ì´ë“œ

í…ŒìŠ¤íŠ¸ ê°œì„  ì œì•ˆì´ë‚˜ ìƒˆë¡œìš´ í…ŒìŠ¤íŠ¸ ì¼€ì´ìŠ¤ ì¶”ê°€ëŠ” ì´ìŠˆë¥¼ ìƒì„±í•´ ì£¼ì„¸ìš”.

---

**ë§ˆì§€ë§‰ ì—…ë°ì´íŠ¸**: 2025-08-05
**ë²„ì „**: 1.0 